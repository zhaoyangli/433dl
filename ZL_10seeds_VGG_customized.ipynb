{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L2HAC92PIGlF",
        "outputId": "55e835d8-707f-4058-e9f2-048422626052"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Expected noise level: 0.3, Actual changed labels: 0.30\n",
            "Noise application is correct: True\n",
            "Expected noise level: 0, Actual changed labels: 0.00\n",
            "Noise application is correct: True\n",
            "Expected asymmetric noise level: 0.15, Actual changed labels: 0.15\n",
            "Asymmetric noise application is correct: True\n",
            "####### Training with Seed: 0 type: symmetric noise level: 0.1 ########\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/22\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "from matplotlib import pyplot\n",
        "from keras.datasets import cifar10\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dropout\n",
        "from keras.optimizers import SGD\n",
        "import numpy as np\n",
        "import random\n",
        "# load train and test dataset\n",
        "def load_dataset():\n",
        "\t# load dataset\n",
        "\t(trainX, trainY), (testX, testY) = cifar10.load_data()\n",
        "\t# one hot encode target values\n",
        "\ttrainY = to_categorical(trainY)\n",
        "\ttestY = to_categorical(testY)\n",
        "\treturn trainX, trainY, testX, testY\n",
        "\n",
        "def apply_noise_to_labels(labels, noise_level, noise_type='symmetric'):\n",
        "    noisy_labels = labels.copy()\n",
        "    n_classes = 10  # CIFAR-10 has 10 classes\n",
        "    label_mapping = {9: 1, 2: 0, 4: 7, 3: 5, 5: 3}  # Asymmetric mapping\n",
        "\n",
        "    for i in range(len(noisy_labels)):\n",
        "        if random.random() < noise_level:\n",
        "            if noise_type == 'symmetric':\n",
        "                # Create a list of possible labels excluding the original one\n",
        "                possible_labels = list(range(n_classes))\n",
        "                possible_labels.remove(noisy_labels[i])\n",
        "                noisy_labels[i] = random.choice(possible_labels)\n",
        "            elif noise_type == 'asymmetric':\n",
        "                # Only apply noise to labels that are in the asymmetric mapping\n",
        "                if noisy_labels[i] in label_mapping:\n",
        "                    noisy_labels[i] = label_mapping[noisy_labels[i]]\n",
        "    return to_categorical(noisy_labels, num_classes=n_classes)\n",
        "\n",
        "\n",
        "def verify_noise(labels, noisy_labels, noise_level):\n",
        "    total_labels = len(labels)\n",
        "    num_changed = np.sum(np.argmax(labels, axis=1) != np.argmax(noisy_labels, axis=1))\n",
        "    changed_percentage = num_changed / total_labels\n",
        "    print(f\"Expected noise level: {noise_level}, Actual changed labels: {changed_percentage:.2f}\")\n",
        "    return abs(changed_percentage - noise_level) < 0.05  # Allowing a small deviation\n",
        "\n",
        "# Example usage\n",
        "trainX, trainY, testX, testY = load_dataset()\n",
        "noisy_trainY = apply_noise_to_labels(np.argmax(trainY, axis=1), 0.3, 'symmetric')\n",
        "is_noise_correct = verify_noise(trainY, noisy_trainY, 0.3)\n",
        "print(\"Noise application is correct:\", is_noise_correct)\n",
        "noisy_trainY = apply_noise_to_labels(np.argmax(trainY, axis=1), 0, 'symmetric')\n",
        "is_noise_correct = verify_noise(trainY, noisy_trainY, 0)\n",
        "print(\"Noise application is correct:\", is_noise_correct)\n",
        "def verify_asymmetric_noise(labels, noisy_labels, noise_level, label_mapping):\n",
        "    # 计算所有标签的总数\n",
        "    total_labels = len(labels)\n",
        "\n",
        "    # 计算实际改变的标签数量\n",
        "    actual_changes = sum((labels == original) & (noisy_labels != original)\n",
        "                         for original in label_mapping)\n",
        "    total_actual_changes = actual_changes.sum()\n",
        "\n",
        "    # 计算改变标签的比例（基于所有标签的总数）\n",
        "    change_percentage = total_actual_changes / total_labels\n",
        "    print(f\"Expected asymmetric noise level: {noise_level}, Actual changed labels: {change_percentage:.2f}\")\n",
        "    return abs(change_percentage - noise_level) < 0.05  # 允许一定的偏差\n",
        "\n",
        "# 示例使用\n",
        "trainX, trainY, testX, testY = load_dataset()\n",
        "label_mapping = {9: 1, 2: 0, 4: 7, 3: 5, 5: 3}\n",
        "noisy_trainY = apply_noise_to_labels(np.argmax(trainY, axis=1), 0.3, 'asymmetric')\n",
        "is_asymmetric_noise_correct = verify_asymmetric_noise(np.argmax(trainY, axis=1), np.argmax(noisy_trainY, axis=1), 0.15, label_mapping)\n",
        "print(\"Asymmetric noise application is correct:\", is_asymmetric_noise_correct)\n",
        "\n",
        "# baseline model with dropout on the cifar10 dataset\n",
        "import sys\n",
        "from matplotlib import pyplot\n",
        "from keras.datasets import cifar10\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dropout\n",
        "from keras.optimizers import SGD\n",
        "\n",
        "# load train and test dataset\n",
        "def load_dataset():\n",
        "\t# load dataset\n",
        "\t(trainX, trainY), (testX, testY) = cifar10.load_data()\n",
        "\t# one hot encode target values\n",
        "\ttrainY = to_categorical(trainY)\n",
        "\ttestY = to_categorical(testY)\n",
        "\treturn trainX, trainY, testX, testY\n",
        "\n",
        "# scale pixels\n",
        "def prep_pixels(train, test):\n",
        "\t# convert from integers to floats\n",
        "\ttrain_norm = train.astype('float32')\n",
        "\ttest_norm = test.astype('float32')\n",
        "\t# normalize to range 0-1\n",
        "\ttrain_norm = train_norm / 255.0\n",
        "\ttest_norm = test_norm / 255.0\n",
        "\t# return normalized images\n",
        "\treturn train_norm, test_norm\n",
        "\n",
        "# define cnn model\n",
        "def define_model():\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))\n",
        "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Dropout(0.2))\n",
        "\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Dropout(0.2))\n",
        "\tmodel.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Dropout(0.2))\n",
        "\tmodel.add(Flatten())\n",
        "\tmodel.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
        "\tmodel.add(Dropout(0.2))\n",
        "\tmodel.add(Dense(10, activation='softmax'))\n",
        "\t# compile model\n",
        "\topt = SGD(lr=0.001, momentum=0.9)\n",
        "\tmodel.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\treturn model\n",
        "\n",
        "# plot diagnostic learning curves\n",
        "def summarize_diagnostics(history):\n",
        "\t# plot loss\n",
        "\tpyplot.subplot(211)\n",
        "\tpyplot.title('Cross Entropy Loss')\n",
        "\tpyplot.plot(history.history['loss'], color='blue', label='train')\n",
        "\tpyplot.plot(history.history['val_loss'], color='orange', label='test')\n",
        "\t# plot accuracy\n",
        "\tpyplot.subplot(212)\n",
        "\tpyplot.title('Classification Accuracy')\n",
        "\tpyplot.plot(history.history['accuracy'], color='blue', label='train')\n",
        "\tpyplot.plot(history.history['val_accuracy'], color='orange', label='test')\n",
        "\tpyplot.show()\n",
        "\tpyplot.close()\n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "def apply_noise_to_labels(labels, noise_level, noise_type='symmetric'):\n",
        "    noisy_labels = labels.copy()\n",
        "    n_classes = 10  # CIFAR-10 has 10 classes\n",
        "    label_mapping = {9: 1, 2: 0, 4: 7, 3: 5, 5: 3}  # Asymmetric mapping\n",
        "\n",
        "    for i in range(len(noisy_labels)):\n",
        "        if random.random() < noise_level:\n",
        "            if noise_type == 'symmetric':\n",
        "                # Create a list of possible labels excluding the original one\n",
        "                possible_labels = list(range(n_classes))\n",
        "                possible_labels.remove(noisy_labels[i])\n",
        "                noisy_labels[i] = random.choice(possible_labels)\n",
        "            elif noise_type == 'asymmetric':\n",
        "                # Only apply noise to labels that are in the asymmetric mapping\n",
        "                if noisy_labels[i] in label_mapping:\n",
        "                    noisy_labels[i] = label_mapping[noisy_labels[i]]\n",
        "    return to_categorical(noisy_labels, num_classes=n_classes)\n",
        "\n",
        "def run_test_harness(noise_level=0.0, noise_type='symmetric'):\n",
        "    # load dataset\n",
        "    trainX, trainY, testX, testY = load_dataset()\n",
        "\n",
        "    # apply noise to labels\n",
        "    trainY_noisy = apply_noise_to_labels(np.argmax(trainY, axis=1), noise_level, noise_type)\n",
        "\n",
        "    # prepare pixel data\n",
        "    trainX, testX = prep_pixels(trainX, testX)\n",
        "\n",
        "    # define model\n",
        "    model = define_model()\n",
        "\n",
        "    # fit model\n",
        "    history = model.fit(trainX, trainY_noisy, epochs=22, batch_size=64, validation_data=(testX, testY), verbose=2)\n",
        "\n",
        "    # evaluate model\n",
        "    _, acc = model.evaluate(testX, testY, verbose=2)\n",
        "    print(f'Noise Level {noise_level} - Noise Type {noise_type} - Accuracy: {acc * 100.0}%')\n",
        "\n",
        "    # learning curves\n",
        "#     summarize_diagnostics(history)\n",
        "\n",
        "# print (\"\\n\\n\\n\")\n",
        "# print(f\"#######   Training with 0 noise level: ########\")\n",
        "# run_test_harness(0, 'symmetric')\n",
        "import torch\n",
        "noise_levels = [0.1, 0.3, 0.5, 0.8, 0.9]\n",
        "\n",
        "noise_types = ['symmetric']\n",
        "seeds = range(10)  # seeds repo\n",
        "\n",
        "for seed in seeds:\n",
        "    torch.manual_seed(seed)  # 设置随机种子\n",
        "    np.random.seed(seed)  # 对于numpy操作也设置随机种子\n",
        "    random.seed(seed)  # 对于Python内置的random库也设置随机种子\n",
        "\n",
        "    for noise_type in noise_types:\n",
        "        for noise_level in noise_levels:\n",
        "            print(f\"####### Training with Seed: {seed} type: {noise_type} noise level: {noise_level} ########\")\n",
        "            run_test_harness(noise_level, noise_type)\n",
        "            print(\"\\n\\n\\n\")"
      ]
    }
  ]
}