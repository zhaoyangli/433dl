{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "830c423b-64f6-41a0-99f4-7309473b5d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import math\n",
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from d2l import torch as d2l\n",
    "import time\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import collections\n",
    "import math\n",
    "import time\n",
    "import torchvision\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data\n",
    "\n",
    "import datetime\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c580fb-7902-4175-bba0-9427d225af7b",
   "metadata": {},
   "source": [
    "Download data from Kaggle and put them into data folder\n",
    "\n",
    "* `../data/cifar-10/train/[1-50000].png`\n",
    "* `../data/cifar-10/test/[1-300000].png`\n",
    "* `../data/cifar-10/trainLabels.csv`\n",
    "* `../data/cifar-10/sampleSubmission.csv`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f85450dd-79d8-4076-99e7-cdbbae21a96a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on NVIDIA GeForce GTX 1660 Ti\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "from d2l import torch as d2l  \n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    devices = [torch.device('cuda')]\n",
    "    print(f\"Training on {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    devices = [torch.device('cpu')]\n",
    "    print(\"Training on CPU\")\n",
    "\n",
    "\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize(40),\n",
    "    transforms.RandomResizedCrop(32, scale=(0.64, 1.0), ratio=(1.0, 1.0)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])\n",
    "])\n",
    "batch_size = 128\n",
    "\n",
    "\n",
    "test_ds = torchvision.datasets.CIFAR10(root='../data', train=False, download=True, transform=transform_test)\n",
    "\n",
    "\n",
    "full_train_ds = torchvision.datasets.CIFAR10(root='../data', train=True, download=True, transform=transform_train)\n",
    "\n",
    "# split ds\n",
    "valid_ratio = 0.1  \n",
    "num_train = len(full_train_ds)\n",
    "num_valid = int(num_train * valid_ratio)\n",
    "train_ds, valid_ds = random_split(full_train_ds, [num_train - num_valid, num_valid])\n",
    "\n",
    "\n",
    "train_iter = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "valid_iter = DataLoader(valid_ds, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "\n",
    "\n",
    "train_iter = torch.utils.data.DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "test_iter = torch.utils.data.DataLoader(test_ds, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "valid_ratio = 0.1\n",
    "\n",
    "valid_iter = torch.utils.data.DataLoader(valid_ds, batch_size, shuffle=False,\n",
    "                                         drop_last=True)\n",
    "\n",
    "test_iter = torch.utils.data.DataLoader(test_ds, batch_size, shuffle=False,\n",
    "                                        drop_last=False)\n",
    "def get_net():\n",
    "    num_classes = 10\n",
    "    net = d2l.resnet18(num_classes, 3)\n",
    "    return net\n",
    "\n",
    "loss = nn.CrossEntropyLoss(reduction=\"none\")\n",
    "\n",
    "\n",
    "   \n",
    "def train(net1, net2, train_iter, valid_iter, num_epochs, lr, wd, devices, lr_period, lr_decay):\n",
    "    trainer1 = optim.SGD(net1.parameters(), lr=lr, momentum=0.9, weight_decay=wd)\n",
    "    trainer2 = optim.SGD(net2.parameters(), lr=lr, momentum=0.9, weight_decay=wd)\n",
    "    scheduler1 = torch.optim.lr_scheduler.StepLR(trainer1, lr_period, lr_decay)\n",
    "    scheduler2 = torch.optim.lr_scheduler.StepLR(trainer2, lr_period, lr_decay)\n",
    "    total_time = 0\n",
    "    num_batches, timer = len(train_iter), d2l.Timer()\n",
    "    train_loss_list, train_acc_list, valid_acc_list = [], [], []\n",
    "    # net1 = nn.DataParallel(net1, device_ids=devices).to(devices[0])\n",
    "    # net2 = nn.DataParallel(net2, device_ids=devices).to(devices[0])\n",
    "    for epoch in range(num_epochs):\n",
    "        start = time.time()\n",
    "        net1.train()\n",
    "        net2.train()\n",
    "        metric1 = d2l.Accumulator(3)\n",
    "        metric2 = d2l.Accumulator(3)\n",
    "        # Train net1\n",
    "        for i, (features, labels) in enumerate(train_iter):\n",
    "            features, labels = features.to(devices[0]), labels.to(devices[0])\n",
    "            trainer1.zero_grad()\n",
    "            outputs = net1(features)\n",
    "            loss = nn.CrossEntropyLoss()(outputs, labels)\n",
    "            loss.backward()\n",
    "            trainer1.step()\n",
    "            metric1.add(loss * labels.shape[0], d2l.accuracy(outputs, labels), labels.shape[0])\n",
    "\n",
    "        # Train net2\n",
    "        for i, (features, labels) in enumerate(train_iter):\n",
    "            features, labels = features.to(devices[0]), labels.to(devices[0])\n",
    "            trainer2.zero_grad()\n",
    "            outputs = net2(features)\n",
    "            loss = nn.CrossEntropyLoss()(outputs, labels)\n",
    "            loss.backward()\n",
    "            trainer2.step()\n",
    "            metric2.add(loss * labels.shape[0], d2l.accuracy(outputs, labels), labels.shape[0])\n",
    "\n",
    "        # Validation accuracy\n",
    "        valid_acc1 = d2l.evaluate_accuracy_gpu(net1, valid_iter)\n",
    "        valid_acc2 = d2l.evaluate_accuracy_gpu(net2, valid_iter)\n",
    "\n",
    "        # Update learning rate\n",
    "        scheduler1.step()\n",
    "        scheduler2.step()\n",
    "        epoch_time = time.time() - start\n",
    "        total_time += epoch_time\n",
    "        # Print metrics\n",
    "        train_loss1 = metric1[0] / metric1[2]\n",
    "        train_acc1 = metric1[1] / metric1[2]\n",
    "        train_loss2 = metric2[0] / metric2[2]\n",
    "        train_acc2 = metric2[1] / metric2[2]\n",
    "        print(f'Epoch {epoch+1}, Net1 loss {train_loss1:.3f}, accuracy {train_acc1:.3f}, Net2 loss {train_loss2:.3f}, accuracy {train_acc2:.3f}, Valid acc1 {valid_acc1:.3f}, Valid acc2 {valid_acc2:.3f}, time {epoch_time:.0f}')\n",
    "\n",
    "\n",
    "        train_loss_list.append(train_loss1)\n",
    "        train_acc_list.append(train_acc1)\n",
    "        valid_acc_list.append(valid_acc1)\n",
    "    print(f'Time {total_time:.1f} sec')\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(range(1, num_epochs + 1), train_loss_list, label='train_loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(range(1, num_epochs + 1), train_acc_list, label='train_acc')\n",
    "    plt.plot(range(1, num_epochs + 1), valid_acc_list, label='valid_acc')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "\n",
    "    current_time = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    save_dir = f'training_plots'\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    plot_filename = f\"{save_dir}/{current_time}_train_plot_{noise_type}_{noise_level}.png\"\n",
    "    plt.savefig(plot_filename)\n",
    "    plt.close()\n",
    "\n",
    "devices, num_epochs, lr, wd = d2l.try_all_gpus(), 100, 2e-4, 5e-4\n",
    "lr_period, lr_decay, net = 4, 0.9, get_net()\n",
    "\n",
    "# devices, num_epochs, lr, wd = d2l.try_all_gpus(), 100, 0.05, 5e-4\n",
    "# lr_period, lr_decay, net = 50, 0.1, get_net()\n",
    "\n",
    "# devices, num_epochs, lr, wd = d2l.try_all_gpus(), 50, 2e-4, 5e-4\n",
    "# lr_period, lr_decay, net = 4, 0.9, get_net()\n",
    "# # devices, num_epochs, lr, wd = d2l.try_all_gpus(), 100, 0.05, 5e-4\n",
    "# # lr_period, lr_decay, net = 50, 0.1, get_net()\n",
    "# train(net, train_iter, valid_iter, num_epochs, lr, wd, devices, lr_period,\n",
    "#       lr_decay)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8bee9992-26cb-40f0-be81-d7a19cc51c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual noise ratio: 0.59838\n",
      "Some original labels: tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3])\n",
      "Corresponding noisy labels (symmetric): tensor([9, 4, 7, 4, 6, 4, 4, 3, 1, 4])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def add_noise_to_labels(labels, noise_ratio, noise_type='symmetric', num_classes=10):\n",
    "    if noise_type not in ['symmetric', 'asymmetric']:\n",
    "        raise ValueError(\"noise_type should be 'symmetric' or 'asymmetric'\")\n",
    "\n",
    "    noisy_labels = labels.clone()\n",
    "    n = len(labels)\n",
    "\n",
    "    # 对称噪声\n",
    "    if noise_type == 'symmetric':\n",
    "        for i in range(n):\n",
    "            if random.random() < noise_ratio:\n",
    "                noisy_labels[i] = random.choice([l for l in range(num_classes) if l != labels[i]])\n",
    "\n",
    "    # 非对称噪声\n",
    "    elif noise_type == 'asymmetric':\n",
    "        print(\"asy: \", n, \" \", noise_ratio)\n",
    "        # CIFAR-10 specific label mapping\n",
    "        mapping = {9: 1, 2: 0, 4: 7, 3: 5, 5: 3}\n",
    "        for i in range(n):\n",
    "            if random.random() < noise_ratio and labels[i].item() in mapping:\n",
    "                # print(\"change\")\n",
    "                noisy_labels[i] = mapping[labels[i].item()]\n",
    "\n",
    "    return noisy_labels\n",
    "    \n",
    "def verify_noise(original_labels, noisy_labels):\n",
    "    assert len(original_labels) == len(noisy_labels), \"Length of original and noisy labels must be equal\"\n",
    "    changed = (original_labels != noisy_labels).sum().item()\n",
    "    total = len(original_labels)\n",
    "    noise_ratio = changed / total\n",
    "    return noise_ratio\n",
    "\n",
    "\n",
    "# \n",
    "original_labels = torch.tensor([full_train_ds[i][1] for i in range(len(full_train_ds))])\n",
    "\n",
    "# \n",
    "noise_ratio = 0.6  # \n",
    "noisy_labels = add_noise_to_labels(original_labels, noise_ratio, noise_type='symmetric')\n",
    "\n",
    "# verify_noise\n",
    "actual_noise_ratio = verify_noise(original_labels, noisy_labels)\n",
    "print(f\"Actual noise ratio: {actual_noise_ratio}\")\n",
    "print(\"Some original labels:\", original_labels[:10])\n",
    "print(\"Corresponding noisy labels (symmetric):\", noisy_labels[:10])\n",
    "\n",
    "asymmetric_mapping = {9: 1, 2: 0, 4: 7, 3: 5, 5: 3}\n",
    "\n",
    "def calculate_asymmetric_noise_ratio(original_labels, noisy_labels, mapping):\n",
    "\n",
    "    n = len(original_labels)\n",
    "    actual_changes = 0\n",
    "    potential_changes = 0\n",
    "\n",
    "    for i in range(n):\n",
    "        if original_labels[i].item() in mapping:\n",
    "            potential_changes += 1\n",
    "            if noisy_labels[i].item() == mapping[original_labels[i].item()]:\n",
    "                actual_changes += 1\n",
    "\n",
    "    if potential_changes == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return actual_changes / potential_changes\n",
    "\n",
    "\n",
    "noisy_labels_a = add_noise_to_labels(original_labels, noise_ratio, noise_type='asymmetric')\n",
    "print(\"Some original labels:\", original_labels[:10])\n",
    "print(\"Corresponding noisy labels (asymmetric):\", noisy_labels_a[:10])\n",
    "\n",
    "\n",
    "\n",
    "actual_asymmetric_noise_ratio = calculate_asymmetric_noise_ratio(original_labels, noisy_labels_a, asymmetric_mapping)\n",
    "print(f\"Actual asymmetric noise ratio: {actual_asymmetric_noise_ratio}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ac107e27-fa3d-4e35-b0ae-99bb9126eb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_train_harness(noise_level=0.0, noise_type='symmetric'):\n",
    "    # 重新加载数据集以避免标签被多次修改\n",
    "    full_train_ds = torchvision.datasets.CIFAR10(root='../data', train=True, download=True, transform=transform_train)\n",
    "    original_labels = torch.tensor(full_train_ds.targets)\n",
    "\n",
    "    # 应用噪声\n",
    "    if noise_level > 0:\n",
    "        noisy_labels = add_noise_to_labels(original_labels, noise_level, noise_type)\n",
    "        full_train_ds.targets = noisy_labels.tolist()\n",
    "\n",
    "    # 分割训练集和验证集\n",
    "    num_train = len(full_train_ds)\n",
    "    num_valid = int(num_train * valid_ratio)\n",
    "    train_ds, valid_ds = random_split(full_train_ds, [num_train - num_valid, num_valid])\n",
    "\n",
    "    # 创建 DataLoader\n",
    "    train_iter = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "    valid_iter = DataLoader(valid_ds, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "\n",
    "\n",
    "    # 创建模型实例\n",
    "    devices, num_epochs, lr, wd = d2l.try_all_gpus(), 18, 2e-4, 5e-4\n",
    "    lr_period, lr_decay = 4, 0.9\n",
    "    net1 = get_net().to(devices[0])\n",
    "    net2 = get_net().to(devices[0])\n",
    "\n",
    "    # 训练模型\n",
    "    print(\"####### Training model with co-training: ########\")\n",
    "    train(net1, net2, train_iter, valid_iter, num_epochs, lr, wd, devices, lr_period, lr_decay)\n",
    "\n",
    "# print(f\"####### Training model with 0 noise level: ########\")\n",
    "# run_train_harness(0, 'symmetric')\n",
    "# print(\"\\n\\n\\n\")\n",
    "\n",
    "# noise_levels = [0.1, 0.3, 0.5, 0.8]\n",
    "# noise_types = ['symmetric', 'asymmetric']\n",
    "\n",
    "# for noise_type in noise_types:\n",
    "#     for noise_level in noise_levels:\n",
    "#         print(f\"####### Training with {noise_type} noise level: {noise_level} ########\")\n",
    "#         run_train_harness(noise_level, noise_type)\n",
    "#         print(\"\\n\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9ea646db-fb78-46c8-8065-3dff789436aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# noise_types = ['symmetric', 'asymmetric']\n",
    "# for noise_type in noise_types:\n",
    "#     noise_level = 0.1\n",
    "#     print(f\"####### Training with {noise_type} noise level: {noise_level} ########\")\n",
    "#     run_train_harness(noise_level, noise_type)\n",
    "#     print(\"\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e41e707f-e271-41fd-b3e6-8d0654be6ced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####### Training with symmetric noise level: 0.3 ########\n",
      "Files already downloaded and verified\n",
      "####### Training model with co-training: ########\n",
      "Epoch 1, Net1 loss 2.168, accuracy 0.216, Net2 loss 2.161, accuracy 0.216, Valid acc1 0.268, Valid acc2 0.271, time 96\n",
      "Epoch 2, Net1 loss 2.037, accuracy 0.293, Net2 loss 2.036, accuracy 0.293, Valid acc1 0.305, Valid acc2 0.304, time 95\n",
      "Epoch 3, Net1 loss 1.982, accuracy 0.327, Net2 loss 1.984, accuracy 0.327, Valid acc1 0.333, Valid acc2 0.327, time 95\n",
      "Epoch 4, Net1 loss 1.942, accuracy 0.347, Net2 loss 1.945, accuracy 0.348, Valid acc1 0.346, Valid acc2 0.348, time 95\n",
      "Epoch 5, Net1 loss 1.911, accuracy 0.368, Net2 loss 1.915, accuracy 0.367, Valid acc1 0.364, Valid acc2 0.355, time 95\n",
      "Epoch 6, Net1 loss 1.888, accuracy 0.382, Net2 loss 1.889, accuracy 0.380, Valid acc1 0.364, Valid acc2 0.368, time 95\n",
      "Epoch 7, Net1 loss 1.865, accuracy 0.395, Net2 loss 1.869, accuracy 0.391, Valid acc1 0.376, Valid acc2 0.376, time 95\n",
      "Epoch 8, Net1 loss 1.845, accuracy 0.406, Net2 loss 1.850, accuracy 0.399, Valid acc1 0.399, Valid acc2 0.385, time 95\n",
      "Epoch 9, Net1 loss 1.826, accuracy 0.414, Net2 loss 1.832, accuracy 0.412, Valid acc1 0.402, Valid acc2 0.403, time 95\n",
      "Epoch 10, Net1 loss 1.810, accuracy 0.423, Net2 loss 1.814, accuracy 0.421, Valid acc1 0.402, Valid acc2 0.403, time 96\n",
      "Epoch 11, Net1 loss 1.794, accuracy 0.433, Net2 loss 1.802, accuracy 0.429, Valid acc1 0.418, Valid acc2 0.411, time 95\n",
      "Epoch 12, Net1 loss 1.779, accuracy 0.441, Net2 loss 1.787, accuracy 0.434, Valid acc1 0.415, Valid acc2 0.417, time 96\n",
      "Epoch 13, Net1 loss 1.767, accuracy 0.448, Net2 loss 1.774, accuracy 0.443, Valid acc1 0.435, Valid acc2 0.416, time 95\n",
      "Epoch 14, Net1 loss 1.753, accuracy 0.454, Net2 loss 1.760, accuracy 0.448, Valid acc1 0.435, Valid acc2 0.427, time 95\n",
      "Epoch 15, Net1 loss 1.742, accuracy 0.460, Net2 loss 1.750, accuracy 0.454, Valid acc1 0.431, Valid acc2 0.430, time 95\n",
      "Epoch 16, Net1 loss 1.731, accuracy 0.465, Net2 loss 1.739, accuracy 0.461, Valid acc1 0.445, Valid acc2 0.422, time 96\n",
      "Epoch 17, Net1 loss 1.716, accuracy 0.471, Net2 loss 1.726, accuracy 0.466, Valid acc1 0.444, Valid acc2 0.442, time 95\n",
      "Epoch 18, Net1 loss 1.707, accuracy 0.477, Net2 loss 1.715, accuracy 0.472, Valid acc1 0.453, Valid acc2 0.446, time 96\n",
      "Epoch 19, Net1 loss 1.696, accuracy 0.480, Net2 loss 1.709, accuracy 0.474, Valid acc1 0.448, Valid acc2 0.444, time 96\n",
      "Epoch 20, Net1 loss 1.686, accuracy 0.484, Net2 loss 1.702, accuracy 0.475, Valid acc1 0.445, Valid acc2 0.455, time 95\n",
      "Epoch 21, Net1 loss 1.676, accuracy 0.487, Net2 loss 1.688, accuracy 0.483, Valid acc1 0.456, Valid acc2 0.449, time 95\n",
      "Epoch 22, Net1 loss 1.669, accuracy 0.494, Net2 loss 1.679, accuracy 0.488, Valid acc1 0.457, Valid acc2 0.454, time 95\n",
      "Epoch 23, Net1 loss 1.660, accuracy 0.496, Net2 loss 1.670, accuracy 0.491, Valid acc1 0.460, Valid acc2 0.451, time 96\n",
      "Epoch 24, Net1 loss 1.649, accuracy 0.499, Net2 loss 1.664, accuracy 0.494, Valid acc1 0.464, Valid acc2 0.459, time 95\n",
      "Epoch 25, Net1 loss 1.640, accuracy 0.505, Net2 loss 1.653, accuracy 0.498, Valid acc1 0.461, Valid acc2 0.457, time 96\n",
      "Epoch 26, Net1 loss 1.631, accuracy 0.508, Net2 loss 1.646, accuracy 0.501, Valid acc1 0.466, Valid acc2 0.458, time 95\n",
      "Epoch 27, Net1 loss 1.628, accuracy 0.510, Net2 loss 1.639, accuracy 0.504, Valid acc1 0.469, Valid acc2 0.455, time 95\n",
      "Epoch 28, Net1 loss 1.618, accuracy 0.513, Net2 loss 1.629, accuracy 0.506, Valid acc1 0.471, Valid acc2 0.463, time 95\n",
      "Epoch 29, Net1 loss 1.608, accuracy 0.515, Net2 loss 1.621, accuracy 0.512, Valid acc1 0.472, Valid acc2 0.466, time 95\n",
      "Epoch 30, Net1 loss 1.603, accuracy 0.517, Net2 loss 1.615, accuracy 0.515, Valid acc1 0.472, Valid acc2 0.466, time 95\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'metric' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m noise_level \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.3\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m####### Training with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnoise_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m noise level: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnoise_level\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ########\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m \u001b[43mrun_train_harness\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnoise_level\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnoise_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[22], line 30\u001b[0m, in \u001b[0;36mrun_train_harness\u001b[1;34m(noise_level, noise_type)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# 训练模型\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m####### Training model with co-training: ########\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 30\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnet2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr_period\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr_decay\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[20], line 130\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(net1, net2, train_iter, valid_iter, num_epochs, lr, wd, devices, lr_period, lr_decay)\u001b[0m\n\u001b[0;32m    128\u001b[0m     train_acc_list\u001b[38;5;241m.\u001b[39mappend(train_acc1)\n\u001b[0;32m    129\u001b[0m     valid_acc_list\u001b[38;5;241m.\u001b[39mappend(valid_acc1)\n\u001b[1;32m--> 130\u001b[0m measures \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain loss \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mmetric\u001b[49m[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;250m \u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;250m \u001b[39mmetric[\u001b[38;5;241m2\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain acc \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;250m \u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;250m \u001b[39mmetric[\u001b[38;5;241m2\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTime \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtimer\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m sec\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    133\u001b[0m \u001b[38;5;66;03m# 绘制训练图表\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'metric' is not defined"
     ]
    }
   ],
   "source": [
    "noise_types = ['symmetric', 'asymmetric']\n",
    "for noise_type in noise_types:\n",
    "    noise_level = 0.3\n",
    "    print(f\"####### Training with {noise_type} noise level: {noise_level} ########\")\n",
    "    run_train_harness(noise_level, noise_type)\n",
    "    print(\"\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6e734937-f624-41d5-9475-dce24abdd1f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####### Training with asymmetric noise level: 0.3 ########\n",
      "Files already downloaded and verified\n",
      "asy:  50000   0.3\n",
      "####### Training model with co-training: ########\n",
      "Epoch 1, Net1 loss 1.905, accuracy 0.307, Net2 loss 1.899, accuracy 0.308, Valid acc1 0.378, Valid acc2 0.388, time 96\n",
      "Epoch 2, Net1 loss 1.569, accuracy 0.419, Net2 loss 1.572, accuracy 0.420, Valid acc1 0.435, Valid acc2 0.432, time 96\n",
      "Epoch 3, Net1 loss 1.433, accuracy 0.468, Net2 loss 1.446, accuracy 0.464, Valid acc1 0.475, Valid acc2 0.474, time 96\n",
      "Epoch 4, Net1 loss 1.336, accuracy 0.503, Net2 loss 1.354, accuracy 0.500, Valid acc1 0.492, Valid acc2 0.499, time 97\n",
      "Epoch 5, Net1 loss 1.263, accuracy 0.530, Net2 loss 1.283, accuracy 0.521, Valid acc1 0.502, Valid acc2 0.516, time 96\n",
      "Epoch 6, Net1 loss 1.208, accuracy 0.548, Net2 loss 1.221, accuracy 0.543, Valid acc1 0.540, Valid acc2 0.527, time 96\n",
      "Epoch 7, Net1 loss 1.163, accuracy 0.564, Net2 loss 1.171, accuracy 0.563, Valid acc1 0.540, Valid acc2 0.544, time 96\n",
      "Epoch 8, Net1 loss 1.116, accuracy 0.579, Net2 loss 1.130, accuracy 0.574, Valid acc1 0.564, Valid acc2 0.542, time 98\n",
      "Epoch 9, Net1 loss 1.077, accuracy 0.593, Net2 loss 1.089, accuracy 0.588, Valid acc1 0.559, Valid acc2 0.569, time 98\n",
      "Epoch 10, Net1 loss 1.050, accuracy 0.600, Net2 loss 1.050, accuracy 0.601, Valid acc1 0.590, Valid acc2 0.579, time 98\n",
      "Epoch 11, Net1 loss 1.019, accuracy 0.611, Net2 loss 1.027, accuracy 0.610, Valid acc1 0.581, Valid acc2 0.575, time 98\n",
      "Epoch 12, Net1 loss 0.998, accuracy 0.618, Net2 loss 0.998, accuracy 0.618, Valid acc1 0.605, Valid acc2 0.596, time 98\n",
      "Epoch 13, Net1 loss 0.972, accuracy 0.627, Net2 loss 0.968, accuracy 0.629, Valid acc1 0.594, Valid acc2 0.599, time 96\n",
      "Epoch 14, Net1 loss 0.952, accuracy 0.633, Net2 loss 0.946, accuracy 0.635, Valid acc1 0.596, Valid acc2 0.607, time 97\n",
      "Epoch 15, Net1 loss 0.929, accuracy 0.641, Net2 loss 0.931, accuracy 0.640, Valid acc1 0.614, Valid acc2 0.599, time 99\n",
      "Epoch 16, Net1 loss 0.912, accuracy 0.646, Net2 loss 0.907, accuracy 0.651, Valid acc1 0.605, Valid acc2 0.613, time 99\n",
      "Epoch 17, Net1 loss 0.894, accuracy 0.655, Net2 loss 0.887, accuracy 0.655, Valid acc1 0.623, Valid acc2 0.624, time 98\n",
      "Epoch 18, Net1 loss 0.879, accuracy 0.660, Net2 loss 0.873, accuracy 0.658, Valid acc1 0.617, Valid acc2 0.626, time 99\n",
      "Time 1752.0 sec\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "noise_types = ['symmetric', 'asymmetric']\n",
    "noise_types = [ 'asymmetric']\n",
    "for noise_type in noise_types:\n",
    "    noise_level = 0.3\n",
    "    print(f\"####### Training with {noise_type} noise level: {noise_level} ########\")\n",
    "    run_train_harness(noise_level, noise_type)\n",
    "    print(\"\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "87d712ba-d401-4048-a91c-ca0a3128124c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####### Training with symmetric noise level: 0.5 ########\n",
      "Files already downloaded and verified\n",
      "####### Training model with co-training: ########\n",
      "Epoch 1, Net1 loss 2.253, accuracy 0.165, Net2 loss 2.257, accuracy 0.165, Valid acc1 0.195, Valid acc2 0.201, time 100\n",
      "Epoch 2, Net1 loss 2.199, accuracy 0.212, Net2 loss 2.203, accuracy 0.210, Valid acc1 0.220, Valid acc2 0.222, time 98\n",
      "Epoch 3, Net1 loss 2.178, accuracy 0.231, Net2 loss 2.179, accuracy 0.231, Valid acc1 0.232, Valid acc2 0.231, time 99\n",
      "Epoch 4, Net1 loss 2.160, accuracy 0.248, Net2 loss 2.162, accuracy 0.244, Valid acc1 0.245, Valid acc2 0.250, time 98\n",
      "Epoch 5, Net1 loss 2.146, accuracy 0.256, Net2 loss 2.148, accuracy 0.255, Valid acc1 0.256, Valid acc2 0.252, time 98\n",
      "Epoch 6, Net1 loss 2.136, accuracy 0.265, Net2 loss 2.137, accuracy 0.265, Valid acc1 0.269, Valid acc2 0.263, time 98\n",
      "Epoch 7, Net1 loss 2.126, accuracy 0.273, Net2 loss 2.126, accuracy 0.270, Valid acc1 0.274, Valid acc2 0.268, time 97\n",
      "Epoch 8, Net1 loss 2.114, accuracy 0.282, Net2 loss 2.115, accuracy 0.277, Valid acc1 0.276, Valid acc2 0.277, time 98\n",
      "Epoch 9, Net1 loss 2.105, accuracy 0.285, Net2 loss 2.106, accuracy 0.283, Valid acc1 0.282, Valid acc2 0.282, time 98\n",
      "Epoch 10, Net1 loss 2.097, accuracy 0.290, Net2 loss 2.098, accuracy 0.288, Valid acc1 0.288, Valid acc2 0.278, time 98\n",
      "Epoch 11, Net1 loss 2.091, accuracy 0.295, Net2 loss 2.091, accuracy 0.294, Valid acc1 0.294, Valid acc2 0.292, time 98\n",
      "Epoch 12, Net1 loss 2.083, accuracy 0.299, Net2 loss 2.083, accuracy 0.298, Valid acc1 0.298, Valid acc2 0.287, time 98\n",
      "Epoch 13, Net1 loss 2.075, accuracy 0.306, Net2 loss 2.075, accuracy 0.303, Valid acc1 0.296, Valid acc2 0.294, time 98\n",
      "Epoch 14, Net1 loss 2.069, accuracy 0.309, Net2 loss 2.068, accuracy 0.307, Valid acc1 0.304, Valid acc2 0.304, time 97\n",
      "Epoch 15, Net1 loss 2.060, accuracy 0.314, Net2 loss 2.061, accuracy 0.312, Valid acc1 0.306, Valid acc2 0.290, time 98\n",
      "Epoch 16, Net1 loss 2.057, accuracy 0.317, Net2 loss 2.056, accuracy 0.315, Valid acc1 0.311, Valid acc2 0.299, time 98\n",
      "Epoch 17, Net1 loss 2.049, accuracy 0.321, Net2 loss 2.047, accuracy 0.319, Valid acc1 0.318, Valid acc2 0.308, time 96\n",
      "Epoch 18, Net1 loss 2.042, accuracy 0.326, Net2 loss 2.041, accuracy 0.321, Valid acc1 0.313, Valid acc2 0.307, time 97\n",
      "Time 1761.6 sec\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "####### Training with asymmetric noise level: 0.5 ########\n",
      "Files already downloaded and verified\n",
      "asy:  50000   0.5\n",
      "####### Training model with co-training: ########\n",
      "Epoch 1, Net1 loss 1.855, accuracy 0.328, Net2 loss 1.868, accuracy 0.320, Valid acc1 0.403, Valid acc2 0.406, time 96\n",
      "Epoch 2, Net1 loss 1.555, accuracy 0.432, Net2 loss 1.551, accuracy 0.436, Valid acc1 0.436, Valid acc2 0.450, time 96\n",
      "Epoch 3, Net1 loss 1.442, accuracy 0.469, Net2 loss 1.421, accuracy 0.477, Valid acc1 0.467, Valid acc2 0.482, time 96\n",
      "Epoch 4, Net1 loss 1.351, accuracy 0.501, Net2 loss 1.336, accuracy 0.506, Valid acc1 0.490, Valid acc2 0.503, time 96\n",
      "Epoch 5, Net1 loss 1.275, accuracy 0.526, Net2 loss 1.257, accuracy 0.531, Valid acc1 0.517, Valid acc2 0.515, time 96\n",
      "Epoch 6, Net1 loss 1.216, accuracy 0.546, Net2 loss 1.203, accuracy 0.548, Valid acc1 0.516, Valid acc2 0.536, time 96\n",
      "Epoch 7, Net1 loss 1.167, accuracy 0.559, Net2 loss 1.158, accuracy 0.560, Valid acc1 0.545, Valid acc2 0.532, time 96\n",
      "Epoch 8, Net1 loss 1.127, accuracy 0.572, Net2 loss 1.114, accuracy 0.573, Valid acc1 0.561, Valid acc2 0.555, time 96\n",
      "Epoch 9, Net1 loss 1.089, accuracy 0.582, Net2 loss 1.079, accuracy 0.584, Valid acc1 0.562, Valid acc2 0.552, time 96\n",
      "Epoch 10, Net1 loss 1.059, accuracy 0.592, Net2 loss 1.050, accuracy 0.592, Valid acc1 0.566, Valid acc2 0.567, time 96\n",
      "Epoch 11, Net1 loss 1.031, accuracy 0.597, Net2 loss 1.024, accuracy 0.598, Valid acc1 0.564, Valid acc2 0.581, time 96\n",
      "Epoch 12, Net1 loss 1.006, accuracy 0.607, Net2 loss 0.997, accuracy 0.607, Valid acc1 0.572, Valid acc2 0.571, time 96\n",
      "Epoch 13, Net1 loss 0.984, accuracy 0.612, Net2 loss 0.969, accuracy 0.616, Valid acc1 0.583, Valid acc2 0.587, time 96\n",
      "Epoch 14, Net1 loss 0.963, accuracy 0.619, Net2 loss 0.948, accuracy 0.623, Valid acc1 0.594, Valid acc2 0.594, time 96\n",
      "Epoch 15, Net1 loss 0.948, accuracy 0.623, Net2 loss 0.932, accuracy 0.623, Valid acc1 0.587, Valid acc2 0.600, time 96\n",
      "Epoch 16, Net1 loss 0.928, accuracy 0.628, Net2 loss 0.913, accuracy 0.629, Valid acc1 0.591, Valid acc2 0.596, time 95\n",
      "Epoch 17, Net1 loss 0.910, accuracy 0.631, Net2 loss 0.894, accuracy 0.635, Valid acc1 0.599, Valid acc2 0.603, time 95\n",
      "Epoch 18, Net1 loss 0.889, accuracy 0.636, Net2 loss 0.879, accuracy 0.639, Valid acc1 0.593, Valid acc2 0.609, time 96\n",
      "Time 1728.0 sec\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "noise_types = ['symmetric', 'asymmetric']\n",
    "for noise_type in noise_types:\n",
    "    noise_level = 0.5\n",
    "    print(f\"####### Training with {noise_type} noise level: {noise_level} ########\")\n",
    "    run_train_harness(noise_level, noise_type)\n",
    "    print(\"\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "aef47f42-c2ee-437f-81bb-ad658443698f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####### Training with symmetric noise level: 0.8 ########\n",
      "Files already downloaded and verified\n",
      "####### Training model with co-training: ########\n",
      "Epoch 1, Net1 loss 2.310, accuracy 0.106, Net2 loss 2.313, accuracy 0.104, Valid acc1 0.111, Valid acc2 0.107, time 95\n",
      "Epoch 2, Net1 loss 2.303, accuracy 0.116, Net2 loss 2.305, accuracy 0.109, Valid acc1 0.109, Valid acc2 0.115, time 96\n",
      "Epoch 3, Net1 loss 2.300, accuracy 0.119, Net2 loss 2.301, accuracy 0.117, Valid acc1 0.116, Valid acc2 0.115, time 96\n",
      "Epoch 4, Net1 loss 2.298, accuracy 0.121, Net2 loss 2.298, accuracy 0.122, Valid acc1 0.117, Valid acc2 0.115, time 95\n",
      "Epoch 5, Net1 loss 2.294, accuracy 0.128, Net2 loss 2.297, accuracy 0.125, Valid acc1 0.120, Valid acc2 0.115, time 95\n",
      "Epoch 6, Net1 loss 2.294, accuracy 0.126, Net2 loss 2.293, accuracy 0.128, Valid acc1 0.116, Valid acc2 0.118, time 96\n",
      "Epoch 7, Net1 loss 2.292, accuracy 0.130, Net2 loss 2.292, accuracy 0.131, Valid acc1 0.122, Valid acc2 0.122, time 97\n",
      "Epoch 8, Net1 loss 2.290, accuracy 0.132, Net2 loss 2.290, accuracy 0.131, Valid acc1 0.126, Valid acc2 0.117, time 97\n",
      "Epoch 9, Net1 loss 2.287, accuracy 0.134, Net2 loss 2.289, accuracy 0.135, Valid acc1 0.118, Valid acc2 0.114, time 97\n",
      "Epoch 10, Net1 loss 2.285, accuracy 0.138, Net2 loss 2.286, accuracy 0.139, Valid acc1 0.122, Valid acc2 0.121, time 97\n",
      "Epoch 11, Net1 loss 2.283, accuracy 0.142, Net2 loss 2.285, accuracy 0.138, Valid acc1 0.127, Valid acc2 0.125, time 97\n",
      "Epoch 12, Net1 loss 2.282, accuracy 0.139, Net2 loss 2.284, accuracy 0.140, Valid acc1 0.125, Valid acc2 0.125, time 97\n",
      "Epoch 13, Net1 loss 2.281, accuracy 0.142, Net2 loss 2.281, accuracy 0.142, Valid acc1 0.120, Valid acc2 0.120, time 97\n",
      "Epoch 14, Net1 loss 2.278, accuracy 0.145, Net2 loss 2.280, accuracy 0.143, Valid acc1 0.127, Valid acc2 0.122, time 96\n",
      "Epoch 15, Net1 loss 2.277, accuracy 0.148, Net2 loss 2.278, accuracy 0.144, Valid acc1 0.124, Valid acc2 0.115, time 97\n",
      "Epoch 16, Net1 loss 2.275, accuracy 0.148, Net2 loss 2.276, accuracy 0.147, Valid acc1 0.121, Valid acc2 0.121, time 97\n",
      "Epoch 17, Net1 loss 2.272, accuracy 0.152, Net2 loss 2.274, accuracy 0.149, Valid acc1 0.123, Valid acc2 0.121, time 98\n",
      "Epoch 18, Net1 loss 2.271, accuracy 0.152, Net2 loss 2.272, accuracy 0.151, Valid acc1 0.117, Valid acc2 0.123, time 97\n",
      "Time 1738.1 sec\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "####### Training with asymmetric noise level: 0.8 ########\n",
      "Files already downloaded and verified\n",
      "asy:  50000   0.8\n",
      "####### Training model with co-training: ########\n",
      "Epoch 1, Net1 loss 1.727, accuracy 0.366, Net2 loss 1.730, accuracy 0.367, Valid acc1 0.456, Valid acc2 0.449, time 96\n",
      "Epoch 2, Net1 loss 1.426, accuracy 0.485, Net2 loss 1.426, accuracy 0.485, Valid acc1 0.511, Valid acc2 0.509, time 97\n",
      "Epoch 3, Net1 loss 1.318, accuracy 0.528, Net2 loss 1.310, accuracy 0.531, Valid acc1 0.541, Valid acc2 0.541, time 97\n",
      "Epoch 4, Net1 loss 1.225, accuracy 0.563, Net2 loss 1.220, accuracy 0.566, Valid acc1 0.572, Valid acc2 0.564, time 96\n",
      "Epoch 5, Net1 loss 1.154, accuracy 0.589, Net2 loss 1.149, accuracy 0.595, Valid acc1 0.604, Valid acc2 0.593, time 97\n",
      "Epoch 6, Net1 loss 1.097, accuracy 0.612, Net2 loss 1.096, accuracy 0.613, Valid acc1 0.598, Valid acc2 0.594, time 96\n",
      "Epoch 7, Net1 loss 1.047, accuracy 0.634, Net2 loss 1.052, accuracy 0.627, Valid acc1 0.625, Valid acc2 0.629, time 97\n",
      "Epoch 8, Net1 loss 1.009, accuracy 0.645, Net2 loss 1.008, accuracy 0.643, Valid acc1 0.624, Valid acc2 0.630, time 97\n",
      "Epoch 9, Net1 loss 0.970, accuracy 0.659, Net2 loss 0.973, accuracy 0.657, Valid acc1 0.637, Valid acc2 0.642, time 98\n",
      "Epoch 10, Net1 loss 0.940, accuracy 0.667, Net2 loss 0.943, accuracy 0.670, Valid acc1 0.639, Valid acc2 0.643, time 98\n",
      "Epoch 11, Net1 loss 0.913, accuracy 0.676, Net2 loss 0.921, accuracy 0.673, Valid acc1 0.656, Valid acc2 0.646, time 97\n",
      "Epoch 12, Net1 loss 0.890, accuracy 0.686, Net2 loss 0.897, accuracy 0.681, Valid acc1 0.655, Valid acc2 0.666, time 97\n",
      "Epoch 13, Net1 loss 0.871, accuracy 0.689, Net2 loss 0.874, accuracy 0.691, Valid acc1 0.661, Valid acc2 0.647, time 97\n",
      "Epoch 14, Net1 loss 0.853, accuracy 0.698, Net2 loss 0.856, accuracy 0.697, Valid acc1 0.680, Valid acc2 0.672, time 97\n",
      "Epoch 15, Net1 loss 0.838, accuracy 0.702, Net2 loss 0.837, accuracy 0.705, Valid acc1 0.687, Valid acc2 0.683, time 96\n",
      "Epoch 16, Net1 loss 0.819, accuracy 0.708, Net2 loss 0.818, accuracy 0.710, Valid acc1 0.692, Valid acc2 0.679, time 96\n",
      "Epoch 17, Net1 loss 0.803, accuracy 0.713, Net2 loss 0.803, accuracy 0.713, Valid acc1 0.686, Valid acc2 0.694, time 97\n",
      "Epoch 18, Net1 loss 0.790, accuracy 0.719, Net2 loss 0.790, accuracy 0.719, Valid acc1 0.686, Valid acc2 0.701, time 96\n",
      "Time 1741.8 sec\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "noise_types = ['symmetric', 'asymmetric']\n",
    "for noise_type in noise_types:\n",
    "    noise_level = 0.8\n",
    "    print(f\"####### Training with {noise_type} noise level: {noise_level} ########\")\n",
    "    run_train_harness(noise_level, noise_type)\n",
    "    print(\"\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b560199-74ab-4ffc-b7cd-a39c9747a4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_types = ['asymmetric']\n",
    "for noise_type in noise_types:\n",
    "    noise_level = 0.0\n",
    "    print(f\"####### Training with {noise_type} noise level: {noise_level} ########\")\n",
    "    run_train_harness(noise_level, noise_type)\n",
    "    print(\"\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149a3e35-4b1a-4330-a382-4cb2e0f2fda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_types = ['asymmetric', 'asymmetric']\n",
    "for noise_type in noise_types:\n",
    "    noise_level = 0.1\n",
    "    print(f\"####### Training with {noise_type} noise level: {noise_level} ########\")\n",
    "    run_train_harness(noise_level, noise_type)\n",
    "    print(\"\\n\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
