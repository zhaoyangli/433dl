{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "830c423b-64f6-41a0-99f4-7309473b5d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import math\n",
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from d2l import torch as d2l\n",
    "import time\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import collections\n",
    "import math\n",
    "import time\n",
    "import torchvision\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data\n",
    "\n",
    "import datetime\n",
    "# !pip install tqdm\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "7b60bfa9-22c4-4633-968b-fb0a5d8b3e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# VGG模型定义\n",
    "def vgg_block(num_convs, in_channels, out_channels):\n",
    "    layers = []\n",
    "    for _ in range(num_convs):\n",
    "        layers.append(nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1))\n",
    "        layers.append(nn.ReLU())\n",
    "        in_channels = out_channels\n",
    "    layers.append(nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "def vgg(conv_arch):\n",
    "    conv_blks = []\n",
    "    in_channels = 3  # CIFAR-10是3通道彩色图像\n",
    "    for (num_convs, out_channels) in conv_arch:\n",
    "        conv_blks.append(vgg_block(num_convs, in_channels, out_channels))\n",
    "        in_channels = out_channels\n",
    "\n",
    "    # 构建卷积层\n",
    "    net = nn.Sequential(*conv_blks)\n",
    "\n",
    "    # 计算展平后的尺寸\n",
    "    with torch.no_grad():\n",
    "        # 假设输入尺寸为(1, 3, 32, 32)\n",
    "        sample_input = torch.randn(1, 3, 32, 32)\n",
    "        sample_output = net(sample_input)\n",
    "        flattened_size = sample_output.shape[1] * sample_output.shape[2] * sample_output.shape[3]\n",
    "\n",
    "    # 构建完整的VGG网络\n",
    "    return nn.Sequential(\n",
    "        *conv_blks, nn.Flatten(),\n",
    "        nn.Linear(flattened_size, 4096), nn.ReLU(), nn.Dropout(0.5),\n",
    "        nn.Linear(4096, 4096), nn.ReLU(), nn.Dropout(0.5),\n",
    "        nn.Linear(4096, 10))\n",
    "\n",
    "\n",
    "\n",
    "# ratio = 4\n",
    "conv_arch = ((2, 64), (2, 128), (3, 256), (3, 512), (3, 512))\n",
    "net = vgg(conv_arch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f85450dd-79d8-4076-99e7-cdbbae21a96a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on NVIDIA GeForce GTX 1660 Ti\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "\n",
    "from d2l import torch as d2l  # 确保已经安装了 d2l 包\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    devices = [torch.device('cuda')]\n",
    "    print(f\"Training on {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    devices = [torch.device('cpu')]\n",
    "    print(\"Training on CPU\")\n",
    "\n",
    "\n",
    "# 数据预处理\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize(40),\n",
    "    transforms.RandomResizedCrop(32, scale=(0.64, 1.0), ratio=(1.0, 1.0)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])\n",
    "])\n",
    "batch_size = 128\n",
    "\n",
    "# 加载 CIFAR-10 数据集\n",
    "test_ds = torchvision.datasets.CIFAR10(root='../data', train=False, download=True, transform=transform_test)\n",
    "\n",
    "# 加载 CIFAR-10 训练集\n",
    "full_train_ds = torchvision.datasets.CIFAR10(root='../data', train=True, download=True, transform=transform_train)\n",
    "\n",
    "# 分割训练集和验证集\n",
    "valid_ratio = 0.1  # 比如，使用 10% 的数据作为验证集\n",
    "num_train = len(full_train_ds)\n",
    "num_valid = int(num_train * valid_ratio)\n",
    "train_ds, valid_ds = random_split(full_train_ds, [num_train - num_valid, num_valid])\n",
    "\n",
    "# 创建 DataLoader\n",
    "train_iter = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "valid_iter = DataLoader(valid_ds, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "\n",
    "# 定义数据加载器\n",
    "train_iter = torch.utils.data.DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "test_iter = torch.utils.data.DataLoader(test_ds, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "valid_ratio = 0.1\n",
    "# 其余定义模型和训练的代码保持不变...\n",
    "valid_iter = torch.utils.data.DataLoader(valid_ds, batch_size, shuffle=False,\n",
    "                                         drop_last=True)\n",
    "\n",
    "test_iter = torch.utils.data.DataLoader(test_ds, batch_size, shuffle=False,\n",
    "                                        drop_last=False)\n",
    "def get_net():\n",
    "    num_classes = 10\n",
    "    net = d2l.resnet18(num_classes, 3)\n",
    "    return net\n",
    "\n",
    "loss = nn.CrossEntropyLoss(reduction=\"none\")\n",
    "\n",
    "def train(net, train_iter, valid_iter, num_epochs, lr, wd, devices, lr_period,\n",
    "          lr_decay):\n",
    "    trainer = torch.optim.SGD(net.parameters(), lr=lr, momentum=0.9,\n",
    "                              weight_decay=wd)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(trainer, lr_period, lr_decay)\n",
    "    num_batches, timer = len(train_iter), d2l.Timer()\n",
    "    legend = ['train loss', 'train acc']\n",
    "    if valid_iter is not None:\n",
    "        legend.append('valid acc')\n",
    "    # animator = d2l.Animator(xlabel='epoch', xlim=[1, num_epochs],\n",
    "    #                         legend=legend)\n",
    "    net = nn.DataParallel(net, device_ids=devices).to(devices[0])\n",
    "    train_loss_list, train_acc_list, valid_acc_list = [], [], []\n",
    "    total_time = 0\n",
    "    for epoch in range(num_epochs):\n",
    "    # for epoch in tqdm(range(num_epochs), desc='Training Progress'):        \n",
    "        net.train()\n",
    "        metric = d2l.Accumulator(3)\n",
    "        start = time.time()\n",
    "        for i, (features, labels) in enumerate(train_iter):\n",
    "            timer.start()\n",
    "            l, acc = d2l.train_batch_ch13(net, features, labels.to(devices[0]), loss, trainer, devices)\n",
    "            metric.add(l, acc, labels.shape[0])\n",
    "            timer.stop()\n",
    "            # if (i + 1) % (num_batches // 5) == 0 or i == num_batches - 1:\n",
    "                # animator.add(epoch + (i + 1) / num_batches,\n",
    "                #              (metric[0] / metric[2], metric[1] / metric[2],\n",
    "                #               None))\n",
    "        train_loss, train_acc = metric[0] / metric[2], metric[1] / metric[2]                          \n",
    "        epoch_time = time.time() - start\n",
    "        total_time += epoch_time\n",
    "        # print(f'Epoch {epoch + 1}, Loss {metric[0] / metric[2]:.3f}, Train acc {metric[1] / metric[2]:.3f}, Time {timer.sum():.1f} sec')\n",
    "        if valid_iter is not None:\n",
    "            valid_acc = d2l.evaluate_accuracy_gpu(net, valid_iter)\n",
    "            # animator.add(epoch + 1, (None, None, valid_acc))\n",
    "        print(f\"{epoch+1}/{num_epochs} - {epoch_time:.0f}s - loss: {train_loss:.4f} - accuracy: {train_acc:.4f} - val_accuracy: {valid_acc:.4f} - {epoch_time:.0f}s/epoch - {timer.avg():.0f}ms/step\")\n",
    "        scheduler.step()\n",
    "        train_loss_list.append(train_loss)\n",
    "        train_acc_list.append(train_acc)\n",
    "        valid_acc_list.append(valid_acc)\n",
    "    measures = (f'train loss {metric[0] / metric[2]:.3f}',f'train acc {metric[1] / metric[2]:.3f}')\n",
    "    # if valid_iter is not None:\n",
    "    #     measures += f', valid acc {valid_acc:.3f}'\n",
    "    print(f'Time {total_time:.1f} sec')\n",
    "    # print(measures + f'\\n{metric[2] * num_epochs / timer.sum():.1f}'\n",
    "    #       f' examples/sec on {str(devices)}')\n",
    "    # 保存训练图表\n",
    "    # save_dir = 'training_plots'\n",
    "    # os.makedirs(save_dir, exist_ok=True)\n",
    "    # plot_filename = f\"{save_dir}/train_plot_{noise_type}_{noise_level}.png\"\n",
    "    # plt.savefig(plot_filename)\n",
    "    # plt.close()\n",
    "\n",
    "    # 绘制训练图表\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(range(1, num_epochs + 1), train_loss_list, label='train_loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(range(1, num_epochs + 1), train_acc_list, label='train_acc')\n",
    "    plt.plot(range(1, num_epochs + 1), valid_acc_list, label='valid_acc')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    # 保存训练图表\n",
    "    current_time = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    save_dir = f'training_plots'\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    plot_filename = f\"{save_dir}/{current_time}_train_plot_{noise_type}_{noise_level}.png\"\n",
    "    plt.savefig(plot_filename)\n",
    "    plt.close()\n",
    "\n",
    "# devices, num_epochs, lr, wd = d2l.try_all_gpus(), 100, 2e-4, 5e-4\n",
    "# lr_period, lr_decay, net = 4, 0.9, get_net()\n",
    "\n",
    "# devices, num_epochs, lr, wd = d2l.try_all_gpus(), 100, 0.05, 5e-4\n",
    "# lr_period, lr_decay, net = 50, 0.1, get_net()\n",
    "\n",
    "# devices, num_epochs, lr, wd = d2l.try_all_gpus(), 50, 2e-4, 5e-4\n",
    "# lr_period, lr_decay, net = 4, 0.9, get_net()\n",
    "# # devices, num_epochs, lr, wd = d2l.try_all_gpus(), 100, 0.05, 5e-4\n",
    "# # lr_period, lr_decay, net = 50, 0.1, get_net()\n",
    "# train(net, train_iter, valid_iter, num_epochs, lr, wd, devices, lr_period,\n",
    "#       lr_decay)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "8bee9992-26cb-40f0-be81-d7a19cc51c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual noise ratio: 0.79622\n",
      "Some original labels: tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3])\n",
      "Corresponding noisy labels (symmetric): tensor([3, 9, 0, 3, 1, 3, 9, 9, 4, 1])\n",
      "asy:  50000   0.8\n",
      "Some original labels: tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3])\n",
      "Corresponding noisy labels (asymmetric): tensor([6, 1, 1, 4, 1, 1, 0, 7, 8, 3])\n",
      "Actual asymmetric noise ratio: 0.7958\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def add_noise_to_labels(labels, noise_ratio, noise_type='symmetric', num_classes=10):\n",
    "    if noise_type not in ['symmetric', 'asymmetric']:\n",
    "        raise ValueError(\"noise_type should be 'symmetric' or 'asymmetric'\")\n",
    "\n",
    "    noisy_labels = labels.clone()\n",
    "    n = len(labels)\n",
    "\n",
    "    # 对称噪声\n",
    "    if noise_type == 'symmetric':\n",
    "        for i in range(n):\n",
    "            if random.random() < noise_ratio:\n",
    "                noisy_labels[i] = random.choice([l for l in range(num_classes) if l != labels[i]])\n",
    "\n",
    "    # 非对称噪声\n",
    "    elif noise_type == 'asymmetric':\n",
    "        print(\"asy: \", n, \" \", noise_ratio)\n",
    "        # CIFAR-10 specific label mapping\n",
    "        mapping = {9: 1, 2: 0, 4: 7, 3: 5, 5: 3}\n",
    "        for i in range(n):\n",
    "            if random.random() < noise_ratio and labels[i].item() in mapping:\n",
    "                # print(\"change\")\n",
    "                noisy_labels[i] = mapping[labels[i].item()]\n",
    "\n",
    "    return noisy_labels\n",
    "    \n",
    "def verify_noise(original_labels, noisy_labels):\n",
    "    assert len(original_labels) == len(noisy_labels), \"Length of original and noisy labels must be equal\"\n",
    "    changed = (original_labels != noisy_labels).sum().item()\n",
    "    total = len(original_labels)\n",
    "    noise_ratio = changed / total\n",
    "    return noise_ratio\n",
    "\n",
    "# 假设 labels 是一个 PyTorch 张量，包含 CIFAR 数据集的标签\n",
    "\n",
    "# 提取训练集的标签\n",
    "original_labels = torch.tensor([full_train_ds[i][1] for i in range(len(full_train_ds))])\n",
    "\n",
    "# 添加噪声\n",
    "noise_ratio = 0.8  # 例如，添加 30% 的噪声\n",
    "noisy_labels = add_noise_to_labels(original_labels, noise_ratio, noise_type='symmetric')\n",
    "\n",
    "# 验证噪声添加\n",
    "actual_noise_ratio = verify_noise(original_labels, noisy_labels)\n",
    "print(f\"Actual noise ratio: {actual_noise_ratio}\")\n",
    "print(\"Some original labels:\", original_labels[:10])\n",
    "print(\"Corresponding noisy labels (symmetric):\", noisy_labels[:10])\n",
    "# 假设 original_labels 和 noisy_labels 分别是原始和带噪声的标签\n",
    "# 定义非对称噪声的映射关系\n",
    "asymmetric_mapping = {9: 1, 2: 0, 4: 7, 3: 5, 5: 3}\n",
    "\n",
    "def calculate_asymmetric_noise_ratio(original_labels, noisy_labels, mapping):\n",
    "    \"\"\"计算实际的非对称噪声比例\"\"\"\n",
    "    n = len(original_labels)\n",
    "    actual_changes = 0\n",
    "    potential_changes = 0\n",
    "\n",
    "    for i in range(n):\n",
    "        if original_labels[i].item() in mapping:\n",
    "            potential_changes += 1\n",
    "            if noisy_labels[i].item() == mapping[original_labels[i].item()]:\n",
    "                actual_changes += 1\n",
    "\n",
    "    if potential_changes == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return actual_changes / potential_changes\n",
    "\n",
    "\n",
    "noisy_labels_a = add_noise_to_labels(original_labels, noise_ratio, noise_type='asymmetric')\n",
    "# 检查原始标签和噪声标签是否有差异\n",
    "print(\"Some original labels:\", original_labels[:10])\n",
    "print(\"Corresponding noisy labels (asymmetric):\", noisy_labels_a[:10])\n",
    "\n",
    "\n",
    "# 计算实际的非对称噪声比例\n",
    "actual_asymmetric_noise_ratio = calculate_asymmetric_noise_ratio(original_labels, noisy_labels_a, asymmetric_mapping)\n",
    "print(f\"Actual asymmetric noise ratio: {actual_asymmetric_noise_ratio}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ac107e27-fa3d-4e35-b0ae-99bb9126eb28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####### Training model with 0 noise level: ########\n",
      "Files already downloaded and verified\n",
      "1/40 - 15s - loss: 2.3040 - accuracy: 0.0968 - val_accuracy: 0.0974 - 15s/epoch - 0ms/step\n",
      "2/40 - 15s - loss: 2.3040 - accuracy: 0.0993 - val_accuracy: 0.0972 - 15s/epoch - 0ms/step\n",
      "3/40 - 16s - loss: 2.3037 - accuracy: 0.1018 - val_accuracy: 0.0972 - 16s/epoch - 0ms/step\n",
      "4/40 - 15s - loss: 2.1907 - accuracy: 0.1389 - val_accuracy: 0.2110 - 15s/epoch - 0ms/step\n",
      "5/40 - 15s - loss: 1.9024 - accuracy: 0.2336 - val_accuracy: 0.2540 - 15s/epoch - 0ms/step\n",
      "6/40 - 15s - loss: 1.6985 - accuracy: 0.3403 - val_accuracy: 0.3612 - 15s/epoch - 0ms/step\n",
      "7/40 - 15s - loss: 1.5117 - accuracy: 0.4285 - val_accuracy: 0.4718 - 15s/epoch - 0ms/step\n",
      "8/40 - 15s - loss: 1.3374 - accuracy: 0.5142 - val_accuracy: 0.5396 - 15s/epoch - 0ms/step\n",
      "9/40 - 15s - loss: 1.1838 - accuracy: 0.5766 - val_accuracy: 0.5878 - 15s/epoch - 0ms/step\n",
      "10/40 - 15s - loss: 1.0919 - accuracy: 0.6136 - val_accuracy: 0.6120 - 15s/epoch - 0ms/step\n",
      "11/40 - 15s - loss: 1.0249 - accuracy: 0.6410 - val_accuracy: 0.6674 - 15s/epoch - 0ms/step\n",
      "12/40 - 15s - loss: 0.9572 - accuracy: 0.6679 - val_accuracy: 0.6634 - 15s/epoch - 0ms/step\n",
      "13/40 - 14s - loss: 0.9004 - accuracy: 0.6905 - val_accuracy: 0.6856 - 14s/epoch - 0ms/step\n",
      "14/40 - 15s - loss: 0.8442 - accuracy: 0.7093 - val_accuracy: 0.6974 - 15s/epoch - 0ms/step\n",
      "15/40 - 15s - loss: 0.8048 - accuracy: 0.7250 - val_accuracy: 0.7058 - 15s/epoch - 0ms/step\n",
      "16/40 - 15s - loss: 0.7741 - accuracy: 0.7349 - val_accuracy: 0.7106 - 15s/epoch - 0ms/step\n",
      "17/40 - 15s - loss: 0.7285 - accuracy: 0.7487 - val_accuracy: 0.7250 - 15s/epoch - 0ms/step\n",
      "18/40 - 15s - loss: 0.7135 - accuracy: 0.7534 - val_accuracy: 0.7302 - 15s/epoch - 0ms/step\n",
      "19/40 - 15s - loss: 0.6823 - accuracy: 0.7661 - val_accuracy: 0.7386 - 15s/epoch - 0ms/step\n",
      "20/40 - 15s - loss: 0.6669 - accuracy: 0.7658 - val_accuracy: 0.7326 - 15s/epoch - 0ms/step\n",
      "21/40 - 15s - loss: 0.6329 - accuracy: 0.7831 - val_accuracy: 0.7478 - 15s/epoch - 0ms/step\n",
      "22/40 - 15s - loss: 0.6183 - accuracy: 0.7857 - val_accuracy: 0.7484 - 15s/epoch - 0ms/step\n",
      "23/40 - 15s - loss: 0.6109 - accuracy: 0.7903 - val_accuracy: 0.7566 - 15s/epoch - 0ms/step\n",
      "24/40 - 15s - loss: 0.5874 - accuracy: 0.7992 - val_accuracy: 0.7596 - 15s/epoch - 0ms/step\n",
      "25/40 - 15s - loss: 0.5657 - accuracy: 0.8057 - val_accuracy: 0.7622 - 15s/epoch - 0ms/step\n",
      "26/40 - 15s - loss: 0.5411 - accuracy: 0.8132 - val_accuracy: 0.7650 - 15s/epoch - 0ms/step\n",
      "27/40 - 15s - loss: 0.5386 - accuracy: 0.8152 - val_accuracy: 0.7626 - 15s/epoch - 0ms/step\n",
      "28/40 - 15s - loss: 0.5228 - accuracy: 0.8185 - val_accuracy: 0.7694 - 15s/epoch - 0ms/step\n",
      "29/40 - 15s - loss: 0.5146 - accuracy: 0.8221 - val_accuracy: 0.7766 - 15s/epoch - 0ms/step\n",
      "30/40 - 16s - loss: 0.4907 - accuracy: 0.8316 - val_accuracy: 0.7768 - 16s/epoch - 0ms/step\n",
      "31/40 - 18s - loss: 0.4893 - accuracy: 0.8321 - val_accuracy: 0.7718 - 18s/epoch - 0ms/step\n",
      "32/40 - 15s - loss: 0.4808 - accuracy: 0.8324 - val_accuracy: 0.7736 - 15s/epoch - 0ms/step\n",
      "33/40 - 15s - loss: 0.4572 - accuracy: 0.8425 - val_accuracy: 0.7810 - 15s/epoch - 0ms/step\n",
      "34/40 - 15s - loss: 0.4480 - accuracy: 0.8444 - val_accuracy: 0.7694 - 15s/epoch - 0ms/step\n",
      "35/40 - 15s - loss: 0.4379 - accuracy: 0.8481 - val_accuracy: 0.7758 - 15s/epoch - 0ms/step\n",
      "36/40 - 15s - loss: 0.4398 - accuracy: 0.8470 - val_accuracy: 0.7824 - 15s/epoch - 0ms/step\n",
      "37/40 - 15s - loss: 0.4186 - accuracy: 0.8549 - val_accuracy: 0.7832 - 15s/epoch - 0ms/step\n",
      "38/40 - 16s - loss: 0.4119 - accuracy: 0.8569 - val_accuracy: 0.7776 - 16s/epoch - 0ms/step\n",
      "39/40 - 15s - loss: 0.4073 - accuracy: 0.8576 - val_accuracy: 0.7846 - 15s/epoch - 0ms/step\n",
      "40/40 - 15s - loss: 0.3934 - accuracy: 0.8628 - val_accuracy: 0.7874 - 15s/epoch - 0ms/step\n",
      "Time 598.1 sec\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def run_train_harness(noise_level=0.0, noise_type='symmetric'):\n",
    "    # 重新加载数据集以避免标签被多次修改\n",
    "    full_train_ds = torchvision.datasets.CIFAR10(root='../data', train=True, download=True, transform=transform_train)\n",
    "    original_labels = torch.tensor(full_train_ds.targets)\n",
    "\n",
    "    # 应用噪声\n",
    "    if noise_level > 0:\n",
    "        noisy_labels = add_noise_to_labels(original_labels, noise_level, noise_type)\n",
    "        full_train_ds.targets = noisy_labels.tolist()\n",
    "\n",
    "    # 分割训练集和验证集\n",
    "    num_train = len(full_train_ds)\n",
    "    num_valid = int(num_train * valid_ratio)\n",
    "    train_ds, valid_ds = random_split(full_train_ds, [num_train - num_valid, num_valid])\n",
    "\n",
    "    # 创建 DataLoader\n",
    "    train_iter = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "    valid_iter = DataLoader(valid_ds, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "    \n",
    "    devices, num_epochs, lr, wd = d2l.try_all_gpus(), 40, 2e-4, 5e-4\n",
    "    lr_period, lr_decay = 4, 0.9\n",
    "    net = vgg(small_conv_arch)\n",
    "\n",
    "    train(net, train_iter, valid_iter, num_epochs, lr, wd, devices, lr_period, lr_decay)\n",
    "    \n",
    "\n",
    "# # 训练没有噪声的模型\n",
    "print(f\"####### Training model with 0 noise level: ########\")\n",
    "run_train_harness(0, 'symmetric')\n",
    "print(\"\\n\\n\\n\")\n",
    "\n",
    "# 用不同的噪声水平和类型训练模型\n",
    "# noise_levels = [0.1, 0.3, 0.5, 0.8]\n",
    "# noise_types = ['symmetric', 'asymmetric']\n",
    "\n",
    "# for noise_type in noise_types:\n",
    "#     for noise_level in noise_levels:\n",
    "#         print(f\"####### Training with {noise_type} noise level: {noise_level} ########\")\n",
    "#         run_train_harness(noise_level, noise_type)\n",
    "#         print(\"\\n\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "9ea646db-fb78-46c8-8065-3dff789436aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####### Training with symmetric noise level: 0.1 ########\n",
      "Files already downloaded and verified\n",
      "1/40 - 15s - loss: 2.3042 - accuracy: 0.0981 - val_accuracy: 0.1010 - 15s/epoch - 0ms/step\n",
      "2/40 - 16s - loss: 2.3038 - accuracy: 0.0994 - val_accuracy: 0.0976 - 16s/epoch - 0ms/step\n",
      "3/40 - 15s - loss: 2.3038 - accuracy: 0.0995 - val_accuracy: 0.1082 - 15s/epoch - 0ms/step\n",
      "4/40 - 15s - loss: 2.3033 - accuracy: 0.0990 - val_accuracy: 0.1098 - 15s/epoch - 0ms/step\n",
      "5/40 - 21s - loss: 2.1158 - accuracy: 0.1729 - val_accuracy: 0.1848 - 21s/epoch - 0ms/step\n",
      "6/40 - 22s - loss: 1.9767 - accuracy: 0.2414 - val_accuracy: 0.2782 - 22s/epoch - 0ms/step\n",
      "7/40 - 21s - loss: 1.8454 - accuracy: 0.3157 - val_accuracy: 0.3044 - 21s/epoch - 0ms/step\n",
      "8/40 - 21s - loss: 1.7176 - accuracy: 0.3829 - val_accuracy: 0.4232 - 21s/epoch - 0ms/step\n",
      "9/40 - 19s - loss: 1.5989 - accuracy: 0.4520 - val_accuracy: 0.4926 - 19s/epoch - 0ms/step\n",
      "10/40 - 21s - loss: 1.5096 - accuracy: 0.4989 - val_accuracy: 0.5036 - 21s/epoch - 0ms/step\n",
      "11/40 - 21s - loss: 1.4308 - accuracy: 0.5361 - val_accuracy: 0.5458 - 21s/epoch - 0ms/step\n",
      "12/40 - 21s - loss: 1.3719 - accuracy: 0.5658 - val_accuracy: 0.5698 - 21s/epoch - 0ms/step\n",
      "13/40 - 17s - loss: 1.3073 - accuracy: 0.5931 - val_accuracy: 0.6018 - 17s/epoch - 0ms/step\n",
      "14/40 - 20s - loss: 1.2632 - accuracy: 0.6116 - val_accuracy: 0.6008 - 20s/epoch - 0ms/step\n",
      "15/40 - 16s - loss: 1.2206 - accuracy: 0.6287 - val_accuracy: 0.6110 - 16s/epoch - 0ms/step\n",
      "16/40 - 19s - loss: 1.1929 - accuracy: 0.6398 - val_accuracy: 0.6256 - 19s/epoch - 0ms/step\n",
      "17/40 - 16s - loss: 1.1600 - accuracy: 0.6533 - val_accuracy: 0.6230 - 16s/epoch - 0ms/step\n",
      "18/40 - 19s - loss: 1.1319 - accuracy: 0.6636 - val_accuracy: 0.6300 - 19s/epoch - 0ms/step\n",
      "19/40 - 18s - loss: 1.1172 - accuracy: 0.6699 - val_accuracy: 0.6370 - 18s/epoch - 0ms/step\n",
      "20/40 - 20s - loss: 1.0945 - accuracy: 0.6796 - val_accuracy: 0.6432 - 20s/epoch - 0ms/step\n",
      "21/40 - 20s - loss: 1.0709 - accuracy: 0.6885 - val_accuracy: 0.6578 - 20s/epoch - 0ms/step\n",
      "22/40 - 19s - loss: 1.0554 - accuracy: 0.6932 - val_accuracy: 0.6676 - 19s/epoch - 0ms/step\n",
      "23/40 - 19s - loss: 1.0341 - accuracy: 0.7012 - val_accuracy: 0.6542 - 19s/epoch - 0ms/step\n",
      "24/40 - 16s - loss: 1.0286 - accuracy: 0.7040 - val_accuracy: 0.6616 - 16s/epoch - 0ms/step\n",
      "25/40 - 20s - loss: 1.0069 - accuracy: 0.7123 - val_accuracy: 0.6576 - 20s/epoch - 0ms/step\n",
      "26/40 - 16s - loss: 0.9953 - accuracy: 0.7142 - val_accuracy: 0.6558 - 16s/epoch - 0ms/step\n",
      "27/40 - 20s - loss: 0.9784 - accuracy: 0.7218 - val_accuracy: 0.6786 - 20s/epoch - 0ms/step\n",
      "28/40 - 18s - loss: 0.9714 - accuracy: 0.7249 - val_accuracy: 0.6646 - 18s/epoch - 0ms/step\n",
      "29/40 - 19s - loss: 0.9525 - accuracy: 0.7312 - val_accuracy: 0.6780 - 19s/epoch - 0ms/step\n",
      "30/40 - 19s - loss: 0.9444 - accuracy: 0.7340 - val_accuracy: 0.6744 - 19s/epoch - 0ms/step\n",
      "31/40 - 19s - loss: 0.9352 - accuracy: 0.7374 - val_accuracy: 0.6642 - 19s/epoch - 0ms/step\n",
      "32/40 - 19s - loss: 0.9294 - accuracy: 0.7412 - val_accuracy: 0.6662 - 19s/epoch - 0ms/step\n",
      "33/40 - 17s - loss: 0.9058 - accuracy: 0.7489 - val_accuracy: 0.6676 - 17s/epoch - 0ms/step\n",
      "34/40 - 20s - loss: 0.8998 - accuracy: 0.7491 - val_accuracy: 0.6792 - 20s/epoch - 0ms/step\n",
      "35/40 - 16s - loss: 0.8889 - accuracy: 0.7511 - val_accuracy: 0.6762 - 16s/epoch - 0ms/step\n",
      "36/40 - 20s - loss: 0.8855 - accuracy: 0.7543 - val_accuracy: 0.6792 - 20s/epoch - 0ms/step\n",
      "37/40 - 17s - loss: 0.8700 - accuracy: 0.7594 - val_accuracy: 0.6832 - 17s/epoch - 0ms/step\n",
      "38/40 - 20s - loss: 0.8561 - accuracy: 0.7622 - val_accuracy: 0.6798 - 20s/epoch - 0ms/step\n",
      "39/40 - 20s - loss: 0.8542 - accuracy: 0.7635 - val_accuracy: 0.6858 - 20s/epoch - 0ms/step\n",
      "40/40 - 20s - loss: 0.8485 - accuracy: 0.7659 - val_accuracy: 0.6840 - 20s/epoch - 0ms/step\n",
      "Time 746.4 sec\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "####### Training with asymmetric noise level: 0.1 ########\n",
      "Files already downloaded and verified\n",
      "asy:  50000   0.1\n",
      "1/40 - 19s - loss: 2.3012 - accuracy: 0.1073 - val_accuracy: 0.1138 - 19s/epoch - 0ms/step\n",
      "2/40 - 17s - loss: 2.3010 - accuracy: 0.1111 - val_accuracy: 0.1098 - 17s/epoch - 0ms/step\n",
      "3/40 - 20s - loss: 2.3010 - accuracy: 0.1106 - val_accuracy: 0.1098 - 20s/epoch - 0ms/step\n",
      "4/40 - 16s - loss: 2.2876 - accuracy: 0.1220 - val_accuracy: 0.1644 - 16s/epoch - 0ms/step\n",
      "5/40 - 20s - loss: 1.9868 - accuracy: 0.2129 - val_accuracy: 0.2616 - 20s/epoch - 0ms/step\n",
      "6/40 - 16s - loss: 1.8029 - accuracy: 0.2998 - val_accuracy: 0.3564 - 16s/epoch - 0ms/step\n",
      "7/40 - 20s - loss: 1.5777 - accuracy: 0.3985 - val_accuracy: 0.4174 - 20s/epoch - 0ms/step\n",
      "8/40 - 19s - loss: 1.4214 - accuracy: 0.4720 - val_accuracy: 0.4634 - 19s/epoch - 0ms/step\n",
      "9/40 - 20s - loss: 1.2597 - accuracy: 0.5424 - val_accuracy: 0.5604 - 20s/epoch - 0ms/step\n",
      "10/40 - 19s - loss: 1.1705 - accuracy: 0.5793 - val_accuracy: 0.5574 - 19s/epoch - 0ms/step\n",
      "11/40 - 17s - loss: 1.0926 - accuracy: 0.6087 - val_accuracy: 0.5914 - 17s/epoch - 0ms/step\n",
      "12/40 - 20s - loss: 1.0333 - accuracy: 0.6318 - val_accuracy: 0.6408 - 20s/epoch - 0ms/step\n",
      "13/40 - 16s - loss: 0.9651 - accuracy: 0.6593 - val_accuracy: 0.6408 - 16s/epoch - 0ms/step\n",
      "14/40 - 20s - loss: 0.9318 - accuracy: 0.6724 - val_accuracy: 0.6576 - 20s/epoch - 0ms/step\n",
      "15/40 - 16s - loss: 0.8867 - accuracy: 0.6887 - val_accuracy: 0.6650 - 16s/epoch - 0ms/step\n",
      "16/40 - 20s - loss: 0.8629 - accuracy: 0.6970 - val_accuracy: 0.6470 - 20s/epoch - 0ms/step\n",
      "17/40 - 19s - loss: 0.8275 - accuracy: 0.7122 - val_accuracy: 0.6878 - 19s/epoch - 0ms/step\n",
      "18/40 - 19s - loss: 0.7936 - accuracy: 0.7223 - val_accuracy: 0.6812 - 19s/epoch - 0ms/step\n",
      "19/40 - 20s - loss: 0.7768 - accuracy: 0.7297 - val_accuracy: 0.6990 - 20s/epoch - 0ms/step\n",
      "20/40 - 17s - loss: 0.7657 - accuracy: 0.7316 - val_accuracy: 0.7102 - 17s/epoch - 0ms/step\n",
      "21/40 - 20s - loss: 0.7302 - accuracy: 0.7464 - val_accuracy: 0.7026 - 20s/epoch - 0ms/step\n",
      "22/40 - 16s - loss: 0.7132 - accuracy: 0.7523 - val_accuracy: 0.6904 - 16s/epoch - 0ms/step\n",
      "23/40 - 19s - loss: 0.7093 - accuracy: 0.7510 - val_accuracy: 0.7184 - 19s/epoch - 0ms/step\n",
      "24/40 - 16s - loss: 0.6948 - accuracy: 0.7608 - val_accuracy: 0.7222 - 16s/epoch - 0ms/step\n",
      "25/40 - 19s - loss: 0.6707 - accuracy: 0.7666 - val_accuracy: 0.7198 - 19s/epoch - 0ms/step\n",
      "26/40 - 18s - loss: 0.6593 - accuracy: 0.7708 - val_accuracy: 0.7282 - 18s/epoch - 0ms/step\n",
      "27/40 - 19s - loss: 0.6458 - accuracy: 0.7769 - val_accuracy: 0.7218 - 19s/epoch - 0ms/step\n",
      "28/40 - 19s - loss: 0.6356 - accuracy: 0.7798 - val_accuracy: 0.7312 - 19s/epoch - 0ms/step\n",
      "29/40 - 19s - loss: 0.6160 - accuracy: 0.7856 - val_accuracy: 0.7326 - 19s/epoch - 0ms/step\n",
      "30/40 - 19s - loss: 0.6023 - accuracy: 0.7926 - val_accuracy: 0.7252 - 19s/epoch - 0ms/step\n",
      "31/40 - 16s - loss: 0.5991 - accuracy: 0.7904 - val_accuracy: 0.7408 - 16s/epoch - 0ms/step\n",
      "32/40 - 19s - loss: 0.5890 - accuracy: 0.7951 - val_accuracy: 0.7362 - 19s/epoch - 0ms/step\n",
      "33/40 - 15s - loss: 0.5657 - accuracy: 0.8006 - val_accuracy: 0.7372 - 15s/epoch - 0ms/step\n",
      "34/40 - 19s - loss: 0.5612 - accuracy: 0.8038 - val_accuracy: 0.7344 - 19s/epoch - 0ms/step\n",
      "35/40 - 17s - loss: 0.5509 - accuracy: 0.8075 - val_accuracy: 0.7392 - 17s/epoch - 0ms/step\n",
      "36/40 - 15s - loss: 0.5417 - accuracy: 0.8112 - val_accuracy: 0.7450 - 15s/epoch - 0ms/step\n",
      "37/40 - 15s - loss: 0.5320 - accuracy: 0.8145 - val_accuracy: 0.7436 - 15s/epoch - 0ms/step\n",
      "38/40 - 14s - loss: 0.5220 - accuracy: 0.8168 - val_accuracy: 0.7530 - 14s/epoch - 0ms/step\n",
      "39/40 - 14s - loss: 0.5159 - accuracy: 0.8197 - val_accuracy: 0.7552 - 14s/epoch - 0ms/step\n",
      "40/40 - 14s - loss: 0.5138 - accuracy: 0.8219 - val_accuracy: 0.7448 - 14s/epoch - 0ms/step\n",
      "Time 710.7 sec\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "noise_types = ['symmetric', 'asymmetric']\n",
    "for noise_type in noise_types:\n",
    "    noise_level = 0.1\n",
    "    print(f\"####### Training with {noise_type} noise level: {noise_level} ########\")\n",
    "    run_train_harness(noise_level, noise_type)\n",
    "    print(\"\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "e41e707f-e271-41fd-b3e6-8d0654be6ced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####### Training with symmetric noise level: 0.3 ########\n",
      "Files already downloaded and verified\n",
      "1/40 - 14s - loss: 2.3041 - accuracy: 0.0984 - val_accuracy: 0.0990 - 14s/epoch - 0ms/step\n",
      "2/40 - 15s - loss: 2.3038 - accuracy: 0.1022 - val_accuracy: 0.0978 - 15s/epoch - 0ms/step\n",
      "3/40 - 14s - loss: 2.3035 - accuracy: 0.1041 - val_accuracy: 0.1016 - 14s/epoch - 0ms/step\n",
      "4/40 - 14s - loss: 2.3037 - accuracy: 0.1007 - val_accuracy: 0.0986 - 14s/epoch - 0ms/step\n",
      "5/40 - 15s - loss: 2.3034 - accuracy: 0.1016 - val_accuracy: 0.1016 - 15s/epoch - 0ms/step\n",
      "6/40 - 15s - loss: 2.3035 - accuracy: 0.0990 - val_accuracy: 0.1040 - 15s/epoch - 0ms/step\n",
      "7/40 - 15s - loss: 2.3034 - accuracy: 0.0994 - val_accuracy: 0.1020 - 15s/epoch - 0ms/step\n",
      "8/40 - 15s - loss: 2.3035 - accuracy: 0.0979 - val_accuracy: 0.0968 - 15s/epoch - 0ms/step\n",
      "9/40 - 14s - loss: 2.3032 - accuracy: 0.0998 - val_accuracy: 0.0986 - 14s/epoch - 0ms/step\n",
      "10/40 - 15s - loss: 2.3029 - accuracy: 0.1006 - val_accuracy: 0.1016 - 15s/epoch - 0ms/step\n",
      "11/40 - 15s - loss: 2.2351 - accuracy: 0.1446 - val_accuracy: 0.1614 - 15s/epoch - 0ms/step\n",
      "12/40 - 14s - loss: 2.1651 - accuracy: 0.1705 - val_accuracy: 0.1852 - 14s/epoch - 0ms/step\n",
      "13/40 - 15s - loss: 2.1429 - accuracy: 0.1954 - val_accuracy: 0.2018 - 15s/epoch - 0ms/step\n",
      "14/40 - 15s - loss: 2.1181 - accuracy: 0.2169 - val_accuracy: 0.2234 - 15s/epoch - 0ms/step\n",
      "15/40 - 14s - loss: 2.0738 - accuracy: 0.2504 - val_accuracy: 0.2638 - 14s/epoch - 0ms/step\n",
      "16/40 - 15s - loss: 2.0215 - accuracy: 0.2812 - val_accuracy: 0.3098 - 15s/epoch - 0ms/step\n",
      "17/40 - 14s - loss: 1.9810 - accuracy: 0.3105 - val_accuracy: 0.2910 - 14s/epoch - 0ms/step\n",
      "18/40 - 14s - loss: 1.9525 - accuracy: 0.3343 - val_accuracy: 0.3534 - 14s/epoch - 0ms/step\n",
      "19/40 - 15s - loss: 1.9117 - accuracy: 0.3611 - val_accuracy: 0.3576 - 15s/epoch - 0ms/step\n",
      "20/40 - 15s - loss: 1.8719 - accuracy: 0.3860 - val_accuracy: 0.4120 - 15s/epoch - 0ms/step\n",
      "21/40 - 15s - loss: 1.8329 - accuracy: 0.4051 - val_accuracy: 0.4148 - 15s/epoch - 0ms/step\n",
      "22/40 - 15s - loss: 1.8063 - accuracy: 0.4250 - val_accuracy: 0.4372 - 15s/epoch - 0ms/step\n",
      "23/40 - 15s - loss: 1.7859 - accuracy: 0.4339 - val_accuracy: 0.4396 - 15s/epoch - 0ms/step\n",
      "24/40 - 15s - loss: 1.7616 - accuracy: 0.4474 - val_accuracy: 0.4504 - 15s/epoch - 0ms/step\n",
      "25/40 - 15s - loss: 1.7342 - accuracy: 0.4639 - val_accuracy: 0.4532 - 15s/epoch - 0ms/step\n",
      "26/40 - 15s - loss: 1.7225 - accuracy: 0.4701 - val_accuracy: 0.4532 - 15s/epoch - 0ms/step\n",
      "27/40 - 15s - loss: 1.7084 - accuracy: 0.4742 - val_accuracy: 0.4634 - 15s/epoch - 0ms/step\n",
      "28/40 - 15s - loss: 1.6920 - accuracy: 0.4836 - val_accuracy: 0.4652 - 15s/epoch - 0ms/step\n",
      "29/40 - 15s - loss: 1.6749 - accuracy: 0.4928 - val_accuracy: 0.4762 - 15s/epoch - 0ms/step\n",
      "30/40 - 15s - loss: 1.6569 - accuracy: 0.5012 - val_accuracy: 0.4742 - 15s/epoch - 0ms/step\n",
      "31/40 - 15s - loss: 1.6536 - accuracy: 0.5041 - val_accuracy: 0.4834 - 15s/epoch - 0ms/step\n",
      "32/40 - 15s - loss: 1.6391 - accuracy: 0.5119 - val_accuracy: 0.4842 - 15s/epoch - 0ms/step\n",
      "33/40 - 14s - loss: 1.6199 - accuracy: 0.5206 - val_accuracy: 0.4976 - 14s/epoch - 0ms/step\n",
      "34/40 - 15s - loss: 1.6067 - accuracy: 0.5258 - val_accuracy: 0.4964 - 15s/epoch - 0ms/step\n",
      "35/40 - 15s - loss: 1.5984 - accuracy: 0.5309 - val_accuracy: 0.4900 - 15s/epoch - 0ms/step\n",
      "36/40 - 15s - loss: 1.5994 - accuracy: 0.5308 - val_accuracy: 0.4940 - 15s/epoch - 0ms/step\n",
      "37/40 - 15s - loss: 1.5747 - accuracy: 0.5392 - val_accuracy: 0.5026 - 15s/epoch - 0ms/step\n",
      "38/40 - 15s - loss: 1.5686 - accuracy: 0.5423 - val_accuracy: 0.5034 - 15s/epoch - 0ms/step\n",
      "39/40 - 15s - loss: 1.5600 - accuracy: 0.5456 - val_accuracy: 0.4838 - 15s/epoch - 0ms/step\n",
      "40/40 - 15s - loss: 1.5519 - accuracy: 0.5496 - val_accuracy: 0.5018 - 15s/epoch - 0ms/step\n",
      "Time 584.5 sec\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "####### Training with asymmetric noise level: 0.3 ########\n",
      "Files already downloaded and verified\n",
      "asy:  50000   0.3\n",
      "1/40 - 15s - loss: 2.2786 - accuracy: 0.1278 - val_accuracy: 0.1264 - 15s/epoch - 0ms/step\n",
      "2/40 - 15s - loss: 2.2779 - accuracy: 0.1304 - val_accuracy: 0.1246 - 15s/epoch - 0ms/step\n",
      "3/40 - 15s - loss: 2.2774 - accuracy: 0.1312 - val_accuracy: 0.1246 - 15s/epoch - 0ms/step\n",
      "4/40 - 15s - loss: 2.1099 - accuracy: 0.1939 - val_accuracy: 0.2390 - 15s/epoch - 0ms/step\n",
      "5/40 - 15s - loss: 1.8558 - accuracy: 0.2851 - val_accuracy: 0.3048 - 15s/epoch - 0ms/step\n",
      "6/40 - 15s - loss: 1.6655 - accuracy: 0.3728 - val_accuracy: 0.4290 - 15s/epoch - 0ms/step\n",
      "7/40 - 15s - loss: 1.5022 - accuracy: 0.4365 - val_accuracy: 0.4714 - 15s/epoch - 0ms/step\n",
      "8/40 - 15s - loss: 1.3618 - accuracy: 0.4897 - val_accuracy: 0.5102 - 15s/epoch - 0ms/step\n",
      "9/40 - 15s - loss: 1.2498 - accuracy: 0.5290 - val_accuracy: 0.5328 - 15s/epoch - 0ms/step\n",
      "10/40 - 15s - loss: 1.1682 - accuracy: 0.5591 - val_accuracy: 0.5532 - 15s/epoch - 0ms/step\n",
      "11/40 - 15s - loss: 1.1046 - accuracy: 0.5809 - val_accuracy: 0.5914 - 15s/epoch - 0ms/step\n",
      "12/40 - 14s - loss: 1.0623 - accuracy: 0.5942 - val_accuracy: 0.5888 - 14s/epoch - 0ms/step\n",
      "13/40 - 14s - loss: 1.0091 - accuracy: 0.6138 - val_accuracy: 0.6068 - 14s/epoch - 0ms/step\n",
      "14/40 - 15s - loss: 0.9775 - accuracy: 0.6264 - val_accuracy: 0.6214 - 15s/epoch - 0ms/step\n",
      "15/40 - 15s - loss: 0.9450 - accuracy: 0.6350 - val_accuracy: 0.6286 - 15s/epoch - 0ms/step\n",
      "16/40 - 15s - loss: 0.9269 - accuracy: 0.6424 - val_accuracy: 0.6186 - 15s/epoch - 0ms/step\n",
      "17/40 - 15s - loss: 0.8860 - accuracy: 0.6548 - val_accuracy: 0.6212 - 15s/epoch - 0ms/step\n",
      "18/40 - 15s - loss: 0.8762 - accuracy: 0.6591 - val_accuracy: 0.6332 - 15s/epoch - 0ms/step\n",
      "19/40 - 15s - loss: 0.8535 - accuracy: 0.6656 - val_accuracy: 0.6546 - 15s/epoch - 0ms/step\n",
      "20/40 - 15s - loss: 0.8382 - accuracy: 0.6731 - val_accuracy: 0.6448 - 15s/epoch - 0ms/step\n",
      "21/40 - 15s - loss: 0.8068 - accuracy: 0.6851 - val_accuracy: 0.6528 - 15s/epoch - 0ms/step\n",
      "22/40 - 15s - loss: 0.7944 - accuracy: 0.6880 - val_accuracy: 0.6508 - 15s/epoch - 0ms/step\n",
      "23/40 - 15s - loss: 0.7823 - accuracy: 0.6897 - val_accuracy: 0.6500 - 15s/epoch - 0ms/step\n",
      "24/40 - 15s - loss: 0.7746 - accuracy: 0.6925 - val_accuracy: 0.6658 - 15s/epoch - 0ms/step\n",
      "25/40 - 15s - loss: 0.7458 - accuracy: 0.7036 - val_accuracy: 0.6618 - 15s/epoch - 0ms/step\n",
      "26/40 - 16s - loss: 0.7412 - accuracy: 0.7052 - val_accuracy: 0.6590 - 16s/epoch - 0ms/step\n",
      "27/40 - 15s - loss: 0.7387 - accuracy: 0.7061 - val_accuracy: 0.6708 - 15s/epoch - 0ms/step\n",
      "28/40 - 15s - loss: 0.7209 - accuracy: 0.7112 - val_accuracy: 0.6568 - 15s/epoch - 0ms/step\n",
      "29/40 - 14s - loss: 0.6987 - accuracy: 0.7198 - val_accuracy: 0.6512 - 14s/epoch - 0ms/step\n",
      "30/40 - 15s - loss: 0.6913 - accuracy: 0.7214 - val_accuracy: 0.6686 - 15s/epoch - 0ms/step\n",
      "31/40 - 15s - loss: 0.6917 - accuracy: 0.7209 - val_accuracy: 0.6766 - 15s/epoch - 0ms/step\n",
      "32/40 - 15s - loss: 0.6843 - accuracy: 0.7243 - val_accuracy: 0.6772 - 15s/epoch - 0ms/step\n",
      "33/40 - 15s - loss: 0.6640 - accuracy: 0.7297 - val_accuracy: 0.6800 - 15s/epoch - 0ms/step\n",
      "34/40 - 15s - loss: 0.6612 - accuracy: 0.7329 - val_accuracy: 0.6774 - 15s/epoch - 0ms/step\n",
      "35/40 - 15s - loss: 0.6473 - accuracy: 0.7356 - val_accuracy: 0.6814 - 15s/epoch - 0ms/step\n",
      "36/40 - 15s - loss: 0.6444 - accuracy: 0.7380 - val_accuracy: 0.6794 - 15s/epoch - 0ms/step\n",
      "37/40 - 15s - loss: 0.6247 - accuracy: 0.7435 - val_accuracy: 0.6846 - 15s/epoch - 0ms/step\n",
      "38/40 - 15s - loss: 0.6168 - accuracy: 0.7452 - val_accuracy: 0.6860 - 15s/epoch - 0ms/step\n",
      "39/40 - 15s - loss: 0.6151 - accuracy: 0.7468 - val_accuracy: 0.6810 - 15s/epoch - 0ms/step\n",
      "40/40 - 15s - loss: 0.6130 - accuracy: 0.7472 - val_accuracy: 0.6884 - 15s/epoch - 0ms/step\n",
      "Time 588.6 sec\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "noise_types = ['symmetric', 'asymmetric']\n",
    "for noise_type in noise_types:\n",
    "    noise_level = 0.3\n",
    "    print(f\"####### Training with {noise_type} noise level: {noise_level} ########\")\n",
    "    run_train_harness(noise_level, noise_type)\n",
    "    print(\"\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "87d712ba-d401-4048-a91c-ca0a3128124c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####### Training with symmetric noise level: 0.5 ########\n",
      "Files already downloaded and verified\n",
      "1/40 - 14s - loss: 2.3042 - accuracy: 0.1001 - val_accuracy: 0.0984 - 14s/epoch - 0ms/step\n",
      "2/40 - 14s - loss: 2.3039 - accuracy: 0.1000 - val_accuracy: 0.1038 - 14s/epoch - 0ms/step\n",
      "3/40 - 15s - loss: 2.3038 - accuracy: 0.0995 - val_accuracy: 0.0962 - 15s/epoch - 0ms/step\n",
      "4/40 - 15s - loss: 2.3037 - accuracy: 0.0986 - val_accuracy: 0.1038 - 15s/epoch - 0ms/step\n",
      "5/40 - 15s - loss: 2.3033 - accuracy: 0.1024 - val_accuracy: 0.1054 - 15s/epoch - 0ms/step\n",
      "6/40 - 15s - loss: 2.3037 - accuracy: 0.0997 - val_accuracy: 0.0938 - 15s/epoch - 0ms/step\n",
      "7/40 - 14s - loss: 2.3034 - accuracy: 0.1006 - val_accuracy: 0.0938 - 14s/epoch - 0ms/step\n",
      "8/40 - 15s - loss: 2.3032 - accuracy: 0.0988 - val_accuracy: 0.1026 - 15s/epoch - 0ms/step\n",
      "9/40 - 15s - loss: 2.3032 - accuracy: 0.1011 - val_accuracy: 0.0984 - 15s/epoch - 0ms/step\n",
      "10/40 - 15s - loss: 2.3031 - accuracy: 0.0997 - val_accuracy: 0.0938 - 15s/epoch - 0ms/step\n",
      "11/40 - 15s - loss: 2.3032 - accuracy: 0.0980 - val_accuracy: 0.0938 - 15s/epoch - 0ms/step\n",
      "12/40 - 15s - loss: 2.3032 - accuracy: 0.0985 - val_accuracy: 0.1022 - 15s/epoch - 0ms/step\n",
      "13/40 - 15s - loss: 2.3030 - accuracy: 0.0976 - val_accuracy: 0.0938 - 15s/epoch - 0ms/step\n",
      "14/40 - 15s - loss: 2.3031 - accuracy: 0.1002 - val_accuracy: 0.0938 - 15s/epoch - 0ms/step\n",
      "15/40 - 14s - loss: 2.3031 - accuracy: 0.0992 - val_accuracy: 0.0938 - 14s/epoch - 0ms/step\n",
      "16/40 - 15s - loss: 2.3031 - accuracy: 0.1002 - val_accuracy: 0.0938 - 15s/epoch - 0ms/step\n",
      "17/40 - 15s - loss: 2.3029 - accuracy: 0.1028 - val_accuracy: 0.0962 - 15s/epoch - 0ms/step\n",
      "18/40 - 15s - loss: 2.3031 - accuracy: 0.0993 - val_accuracy: 0.0962 - 15s/epoch - 0ms/step\n",
      "19/40 - 15s - loss: 2.3030 - accuracy: 0.1006 - val_accuracy: 0.0938 - 15s/epoch - 0ms/step\n",
      "20/40 - 15s - loss: 2.3030 - accuracy: 0.1004 - val_accuracy: 0.1022 - 15s/epoch - 0ms/step\n",
      "21/40 - 15s - loss: 2.3030 - accuracy: 0.0997 - val_accuracy: 0.1048 - 15s/epoch - 0ms/step\n",
      "22/40 - 15s - loss: 2.3029 - accuracy: 0.1016 - val_accuracy: 0.0938 - 15s/epoch - 0ms/step\n",
      "23/40 - 15s - loss: 2.3029 - accuracy: 0.1000 - val_accuracy: 0.1006 - 15s/epoch - 0ms/step\n",
      "24/40 - 15s - loss: 2.3029 - accuracy: 0.0998 - val_accuracy: 0.0938 - 15s/epoch - 0ms/step\n",
      "25/40 - 15s - loss: 2.3030 - accuracy: 0.1012 - val_accuracy: 0.0938 - 15s/epoch - 0ms/step\n",
      "26/40 - 15s - loss: 2.3028 - accuracy: 0.1016 - val_accuracy: 0.1022 - 15s/epoch - 0ms/step\n",
      "27/40 - 15s - loss: 2.3029 - accuracy: 0.1015 - val_accuracy: 0.0962 - 15s/epoch - 0ms/step\n",
      "28/40 - 15s - loss: 2.3028 - accuracy: 0.1015 - val_accuracy: 0.0938 - 15s/epoch - 0ms/step\n",
      "29/40 - 15s - loss: 2.3028 - accuracy: 0.0997 - val_accuracy: 0.1038 - 15s/epoch - 0ms/step\n",
      "30/40 - 26s - loss: 2.3027 - accuracy: 0.1008 - val_accuracy: 0.0938 - 26s/epoch - 0ms/step\n",
      "31/40 - 48s - loss: 2.3027 - accuracy: 0.1006 - val_accuracy: 0.0962 - 48s/epoch - 0ms/step\n",
      "32/40 - 48s - loss: 2.3026 - accuracy: 0.1025 - val_accuracy: 0.1038 - 48s/epoch - 0ms/step\n",
      "33/40 - 47s - loss: 2.3024 - accuracy: 0.1015 - val_accuracy: 0.0984 - 47s/epoch - 0ms/step\n",
      "34/40 - 37s - loss: 2.2985 - accuracy: 0.1111 - val_accuracy: 0.1304 - 37s/epoch - 0ms/step\n",
      "35/40 - 52s - loss: 2.2698 - accuracy: 0.1382 - val_accuracy: 0.1354 - 52s/epoch - 0ms/step\n",
      "36/40 - 52s - loss: 2.2570 - accuracy: 0.1462 - val_accuracy: 0.1624 - 52s/epoch - 0ms/step\n",
      "37/40 - 51s - loss: 2.2325 - accuracy: 0.1605 - val_accuracy: 0.1646 - 51s/epoch - 0ms/step\n",
      "38/40 - 52s - loss: 2.2233 - accuracy: 0.1684 - val_accuracy: 0.1844 - 52s/epoch - 0ms/step\n",
      "39/40 - 51s - loss: 2.2128 - accuracy: 0.1800 - val_accuracy: 0.1910 - 51s/epoch - 0ms/step\n",
      "40/40 - 52s - loss: 2.2018 - accuracy: 0.1906 - val_accuracy: 0.1958 - 52s/epoch - 0ms/step\n",
      "Time 942.0 sec\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "####### Training with asymmetric noise level: 0.5 ########\n",
      "Files already downloaded and verified\n",
      "asy:  50000   0.5\n",
      "1/40 - 50s - loss: 2.2301 - accuracy: 0.1521 - val_accuracy: 0.1616 - 50s/epoch - 0ms/step\n",
      "2/40 - 51s - loss: 2.2278 - accuracy: 0.1464 - val_accuracy: 0.1432 - 51s/epoch - 0ms/step\n",
      "3/40 - 51s - loss: 2.2273 - accuracy: 0.1482 - val_accuracy: 0.1502 - 51s/epoch - 0ms/step\n",
      "4/40 - 36s - loss: 2.1121 - accuracy: 0.1924 - val_accuracy: 0.2576 - 36s/epoch - 0ms/step\n",
      "5/40 - 20s - loss: 1.8443 - accuracy: 0.2911 - val_accuracy: 0.3492 - 20s/epoch - 0ms/step\n",
      "6/40 - 20s - loss: 1.6679 - accuracy: 0.3791 - val_accuracy: 0.4292 - 20s/epoch - 0ms/step\n",
      "7/40 - 20s - loss: 1.4976 - accuracy: 0.4538 - val_accuracy: 0.4954 - 20s/epoch - 0ms/step\n",
      "8/40 - 20s - loss: 1.3297 - accuracy: 0.5143 - val_accuracy: 0.5046 - 20s/epoch - 0ms/step\n",
      "9/40 - 20s - loss: 1.2191 - accuracy: 0.5448 - val_accuracy: 0.5586 - 20s/epoch - 0ms/step\n",
      "10/40 - 20s - loss: 1.1459 - accuracy: 0.5662 - val_accuracy: 0.5678 - 20s/epoch - 0ms/step\n",
      "11/40 - 20s - loss: 1.0857 - accuracy: 0.5806 - val_accuracy: 0.5858 - 20s/epoch - 0ms/step\n",
      "12/40 - 20s - loss: 1.0340 - accuracy: 0.5936 - val_accuracy: 0.6022 - 20s/epoch - 0ms/step\n",
      "13/40 - 20s - loss: 0.9910 - accuracy: 0.6047 - val_accuracy: 0.5920 - 20s/epoch - 0ms/step\n",
      "14/40 - 20s - loss: 0.9619 - accuracy: 0.6106 - val_accuracy: 0.5926 - 20s/epoch - 0ms/step\n",
      "15/40 - 20s - loss: 0.9389 - accuracy: 0.6147 - val_accuracy: 0.6204 - 20s/epoch - 0ms/step\n",
      "16/40 - 20s - loss: 0.9127 - accuracy: 0.6224 - val_accuracy: 0.6084 - 20s/epoch - 0ms/step\n",
      "17/40 - 33s - loss: 0.8906 - accuracy: 0.6282 - val_accuracy: 0.5966 - 33s/epoch - 0ms/step\n",
      "18/40 - 49s - loss: 0.8695 - accuracy: 0.6328 - val_accuracy: 0.6050 - 49s/epoch - 0ms/step\n",
      "19/40 - 49s - loss: 0.8508 - accuracy: 0.6394 - val_accuracy: 0.6208 - 49s/epoch - 0ms/step\n",
      "20/40 - 50s - loss: 0.8406 - accuracy: 0.6420 - val_accuracy: 0.6290 - 50s/epoch - 0ms/step\n",
      "21/40 - 49s - loss: 0.8106 - accuracy: 0.6478 - val_accuracy: 0.6246 - 49s/epoch - 0ms/step\n",
      "22/40 - 51s - loss: 0.7984 - accuracy: 0.6533 - val_accuracy: 0.6226 - 51s/epoch - 0ms/step\n",
      "23/40 - 51s - loss: 0.7887 - accuracy: 0.6559 - val_accuracy: 0.6136 - 51s/epoch - 0ms/step\n",
      "24/40 - 51s - loss: 0.7790 - accuracy: 0.6576 - val_accuracy: 0.6334 - 51s/epoch - 0ms/step\n",
      "25/40 - 52s - loss: 0.7613 - accuracy: 0.6636 - val_accuracy: 0.6194 - 52s/epoch - 0ms/step\n",
      "26/40 - 52s - loss: 0.7539 - accuracy: 0.6619 - val_accuracy: 0.6266 - 52s/epoch - 0ms/step\n",
      "27/40 - 52s - loss: 0.7423 - accuracy: 0.6672 - val_accuracy: 0.6342 - 52s/epoch - 0ms/step\n",
      "28/40 - 52s - loss: 0.7347 - accuracy: 0.6688 - val_accuracy: 0.6292 - 52s/epoch - 0ms/step\n",
      "29/40 - 42s - loss: 0.7132 - accuracy: 0.6771 - val_accuracy: 0.6350 - 42s/epoch - 0ms/step\n",
      "30/40 - 51s - loss: 0.7080 - accuracy: 0.6764 - val_accuracy: 0.6354 - 51s/epoch - 0ms/step\n",
      "31/40 - 51s - loss: 0.6972 - accuracy: 0.6769 - val_accuracy: 0.6360 - 51s/epoch - 0ms/step\n",
      "32/40 - 51s - loss: 0.6865 - accuracy: 0.6793 - val_accuracy: 0.6334 - 51s/epoch - 0ms/step\n",
      "33/40 - 51s - loss: 0.6805 - accuracy: 0.6855 - val_accuracy: 0.6364 - 51s/epoch - 0ms/step\n",
      "34/40 - 51s - loss: 0.6694 - accuracy: 0.6872 - val_accuracy: 0.6382 - 51s/epoch - 0ms/step\n",
      "35/40 - 51s - loss: 0.6592 - accuracy: 0.6907 - val_accuracy: 0.6318 - 51s/epoch - 0ms/step\n",
      "36/40 - 51s - loss: 0.6562 - accuracy: 0.6891 - val_accuracy: 0.6404 - 51s/epoch - 0ms/step\n",
      "37/40 - 46s - loss: 0.6407 - accuracy: 0.6954 - val_accuracy: 0.6380 - 46s/epoch - 0ms/step\n",
      "38/40 - 38s - loss: 0.6315 - accuracy: 0.6994 - val_accuracy: 0.6364 - 38s/epoch - 0ms/step\n",
      "39/40 - 49s - loss: 0.6299 - accuracy: 0.7006 - val_accuracy: 0.6372 - 49s/epoch - 0ms/step\n",
      "40/40 - 52s - loss: 0.6270 - accuracy: 0.7017 - val_accuracy: 0.6342 - 52s/epoch - 0ms/step\n",
      "Time 1601.8 sec\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "noise_types = ['symmetric', 'asymmetric']\n",
    "for noise_type in noise_types:\n",
    "    noise_level = 0.5\n",
    "    print(f\"####### Training with {noise_type} noise level: {noise_level} ########\")\n",
    "    run_train_harness(noise_level, noise_type)\n",
    "    print(\"\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "aef47f42-c2ee-437f-81bb-ad658443698f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####### Training with symmetric noise level: 0.8 ########\n",
      "Files already downloaded and verified\n",
      "1/40 - 52s - loss: 2.3040 - accuracy: 0.1001 - val_accuracy: 0.1022 - 52s/epoch - 0ms/step\n",
      "2/40 - 52s - loss: 2.3040 - accuracy: 0.0994 - val_accuracy: 0.0996 - 52s/epoch - 0ms/step\n",
      "3/40 - 52s - loss: 2.3037 - accuracy: 0.1004 - val_accuracy: 0.1028 - 52s/epoch - 0ms/step\n",
      "4/40 - 52s - loss: 2.3036 - accuracy: 0.1002 - val_accuracy: 0.1012 - 52s/epoch - 0ms/step\n",
      "5/40 - 52s - loss: 2.3034 - accuracy: 0.1016 - val_accuracy: 0.0968 - 52s/epoch - 0ms/step\n",
      "6/40 - 52s - loss: 2.3034 - accuracy: 0.0999 - val_accuracy: 0.1012 - 52s/epoch - 0ms/step\n",
      "7/40 - 52s - loss: 2.3033 - accuracy: 0.0975 - val_accuracy: 0.0996 - 52s/epoch - 0ms/step\n",
      "8/40 - 52s - loss: 2.3033 - accuracy: 0.1008 - val_accuracy: 0.1000 - 52s/epoch - 0ms/step\n",
      "9/40 - 52s - loss: 2.3031 - accuracy: 0.0999 - val_accuracy: 0.1000 - 52s/epoch - 0ms/step\n",
      "10/40 - 52s - loss: 2.3031 - accuracy: 0.0987 - val_accuracy: 0.0968 - 52s/epoch - 0ms/step\n",
      "11/40 - 60s - loss: 2.3032 - accuracy: 0.1007 - val_accuracy: 0.0996 - 60s/epoch - 0ms/step\n",
      "12/40 - 70s - loss: 2.3030 - accuracy: 0.1005 - val_accuracy: 0.0968 - 70s/epoch - 0ms/step\n",
      "13/40 - 33s - loss: 2.3031 - accuracy: 0.1000 - val_accuracy: 0.1022 - 33s/epoch - 0ms/step\n",
      "14/40 - 30s - loss: 2.3030 - accuracy: 0.0990 - val_accuracy: 0.1028 - 30s/epoch - 0ms/step\n",
      "15/40 - 30s - loss: 2.3030 - accuracy: 0.0998 - val_accuracy: 0.1000 - 30s/epoch - 0ms/step\n",
      "16/40 - 30s - loss: 2.3031 - accuracy: 0.0982 - val_accuracy: 0.1072 - 30s/epoch - 0ms/step\n",
      "17/40 - 31s - loss: 2.3029 - accuracy: 0.1005 - val_accuracy: 0.0968 - 31s/epoch - 0ms/step\n",
      "18/40 - 37s - loss: 2.3030 - accuracy: 0.0985 - val_accuracy: 0.0906 - 37s/epoch - 0ms/step\n",
      "19/40 - 38s - loss: 2.3028 - accuracy: 0.1021 - val_accuracy: 0.1000 - 38s/epoch - 0ms/step\n",
      "20/40 - 37s - loss: 2.3031 - accuracy: 0.0988 - val_accuracy: 0.0906 - 37s/epoch - 0ms/step\n",
      "21/40 - 37s - loss: 2.3030 - accuracy: 0.0996 - val_accuracy: 0.0968 - 37s/epoch - 0ms/step\n",
      "22/40 - 37s - loss: 2.3029 - accuracy: 0.0994 - val_accuracy: 0.1000 - 37s/epoch - 0ms/step\n",
      "23/40 - 37s - loss: 2.3030 - accuracy: 0.0967 - val_accuracy: 0.0968 - 37s/epoch - 0ms/step\n",
      "24/40 - 37s - loss: 2.3029 - accuracy: 0.0997 - val_accuracy: 0.1000 - 37s/epoch - 0ms/step\n",
      "25/40 - 37s - loss: 2.3027 - accuracy: 0.1009 - val_accuracy: 0.0906 - 37s/epoch - 0ms/step\n",
      "26/40 - 37s - loss: 2.3029 - accuracy: 0.1012 - val_accuracy: 0.1028 - 37s/epoch - 0ms/step\n",
      "27/40 - 38s - loss: 2.3028 - accuracy: 0.1004 - val_accuracy: 0.0906 - 38s/epoch - 0ms/step\n",
      "28/40 - 37s - loss: 2.3028 - accuracy: 0.0986 - val_accuracy: 0.1000 - 37s/epoch - 0ms/step\n",
      "29/40 - 37s - loss: 2.3028 - accuracy: 0.1024 - val_accuracy: 0.1000 - 37s/epoch - 0ms/step\n",
      "30/40 - 37s - loss: 2.3028 - accuracy: 0.0990 - val_accuracy: 0.1028 - 37s/epoch - 0ms/step\n",
      "31/40 - 37s - loss: 2.3028 - accuracy: 0.1014 - val_accuracy: 0.1022 - 37s/epoch - 0ms/step\n",
      "32/40 - 37s - loss: 2.3028 - accuracy: 0.1000 - val_accuracy: 0.1028 - 37s/epoch - 0ms/step\n",
      "33/40 - 38s - loss: 2.3028 - accuracy: 0.0992 - val_accuracy: 0.1028 - 38s/epoch - 0ms/step\n",
      "34/40 - 37s - loss: 2.3028 - accuracy: 0.0989 - val_accuracy: 0.0968 - 37s/epoch - 0ms/step\n",
      "35/40 - 37s - loss: 2.3028 - accuracy: 0.0977 - val_accuracy: 0.1000 - 37s/epoch - 0ms/step\n",
      "36/40 - 37s - loss: 2.3027 - accuracy: 0.0993 - val_accuracy: 0.0906 - 37s/epoch - 0ms/step\n",
      "37/40 - 38s - loss: 2.3028 - accuracy: 0.1000 - val_accuracy: 0.1028 - 38s/epoch - 0ms/step\n",
      "38/40 - 38s - loss: 2.3027 - accuracy: 0.1005 - val_accuracy: 0.0906 - 38s/epoch - 0ms/step\n",
      "39/40 - 37s - loss: 2.3027 - accuracy: 0.1007 - val_accuracy: 0.1028 - 37s/epoch - 0ms/step\n",
      "40/40 - 37s - loss: 2.3027 - accuracy: 0.1015 - val_accuracy: 0.0968 - 37s/epoch - 0ms/step\n",
      "Time 1657.7 sec\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "####### Training with asymmetric noise level: 0.8 ########\n",
      "Files already downloaded and verified\n",
      "asy:  50000   0.8\n",
      "1/40 - 37s - loss: 2.0905 - accuracy: 0.1800 - val_accuracy: 0.1818 - 37s/epoch - 0ms/step\n",
      "2/40 - 37s - loss: 2.0830 - accuracy: 0.1800 - val_accuracy: 0.1708 - 37s/epoch - 0ms/step\n",
      "3/40 - 37s - loss: 2.0830 - accuracy: 0.1801 - val_accuracy: 0.1840 - 37s/epoch - 0ms/step\n",
      "4/40 - 37s - loss: 2.0832 - accuracy: 0.1804 - val_accuracy: 0.1708 - 37s/epoch - 0ms/step\n",
      "5/40 - 36s - loss: 2.0822 - accuracy: 0.1809 - val_accuracy: 0.1818 - 36s/epoch - 0ms/step\n",
      "6/40 - 38s - loss: 2.0215 - accuracy: 0.2404 - val_accuracy: 0.3408 - 38s/epoch - 0ms/step\n",
      "7/40 - 37s - loss: 1.6553 - accuracy: 0.3817 - val_accuracy: 0.4322 - 37s/epoch - 0ms/step\n",
      "8/40 - 36s - loss: 1.4627 - accuracy: 0.4680 - val_accuracy: 0.5104 - 36s/epoch - 0ms/step\n",
      "9/40 - 36s - loss: 1.2852 - accuracy: 0.5442 - val_accuracy: 0.5726 - 36s/epoch - 0ms/step\n",
      "10/40 - 36s - loss: 1.1741 - accuracy: 0.5882 - val_accuracy: 0.5844 - 36s/epoch - 0ms/step\n",
      "11/40 - 36s - loss: 1.0872 - accuracy: 0.6193 - val_accuracy: 0.6156 - 36s/epoch - 0ms/step\n",
      "12/40 - 36s - loss: 1.0276 - accuracy: 0.6389 - val_accuracy: 0.6184 - 36s/epoch - 0ms/step\n",
      "13/40 - 36s - loss: 0.9561 - accuracy: 0.6654 - val_accuracy: 0.6548 - 36s/epoch - 0ms/step\n",
      "14/40 - 36s - loss: 0.9248 - accuracy: 0.6744 - val_accuracy: 0.6626 - 36s/epoch - 0ms/step\n",
      "15/40 - 36s - loss: 0.8893 - accuracy: 0.6888 - val_accuracy: 0.6682 - 36s/epoch - 0ms/step\n",
      "16/40 - 36s - loss: 0.8673 - accuracy: 0.6970 - val_accuracy: 0.6802 - 36s/epoch - 0ms/step\n",
      "17/40 - 36s - loss: 0.8341 - accuracy: 0.7069 - val_accuracy: 0.6866 - 36s/epoch - 0ms/step\n",
      "18/40 - 36s - loss: 0.8091 - accuracy: 0.7154 - val_accuracy: 0.6870 - 36s/epoch - 0ms/step\n",
      "19/40 - 36s - loss: 0.7859 - accuracy: 0.7225 - val_accuracy: 0.6848 - 36s/epoch - 0ms/step\n",
      "20/40 - 36s - loss: 0.7756 - accuracy: 0.7263 - val_accuracy: 0.6930 - 36s/epoch - 0ms/step\n",
      "21/40 - 36s - loss: 0.7505 - accuracy: 0.7349 - val_accuracy: 0.6850 - 36s/epoch - 0ms/step\n",
      "22/40 - 36s - loss: 0.7383 - accuracy: 0.7378 - val_accuracy: 0.7006 - 36s/epoch - 0ms/step\n",
      "23/40 - 36s - loss: 0.7228 - accuracy: 0.7424 - val_accuracy: 0.7028 - 36s/epoch - 0ms/step\n",
      "24/40 - 36s - loss: 0.7087 - accuracy: 0.7475 - val_accuracy: 0.7120 - 36s/epoch - 0ms/step\n",
      "25/40 - 36s - loss: 0.6863 - accuracy: 0.7544 - val_accuracy: 0.7098 - 36s/epoch - 0ms/step\n",
      "26/40 - 36s - loss: 0.6834 - accuracy: 0.7558 - val_accuracy: 0.7022 - 36s/epoch - 0ms/step\n",
      "27/40 - 36s - loss: 0.6696 - accuracy: 0.7606 - val_accuracy: 0.7074 - 36s/epoch - 0ms/step\n",
      "28/40 - 36s - loss: 0.6561 - accuracy: 0.7652 - val_accuracy: 0.7276 - 36s/epoch - 0ms/step\n",
      "29/40 - 40s - loss: 0.6386 - accuracy: 0.7711 - val_accuracy: 0.7168 - 40s/epoch - 0ms/step\n",
      "30/40 - 39s - loss: 0.6327 - accuracy: 0.7734 - val_accuracy: 0.7194 - 39s/epoch - 0ms/step\n",
      "31/40 - 37s - loss: 0.6217 - accuracy: 0.7740 - val_accuracy: 0.7154 - 37s/epoch - 0ms/step\n",
      "32/40 - 37s - loss: 0.6162 - accuracy: 0.7774 - val_accuracy: 0.7232 - 37s/epoch - 0ms/step\n",
      "33/40 - 37s - loss: 0.5985 - accuracy: 0.7833 - val_accuracy: 0.7182 - 37s/epoch - 0ms/step\n",
      "34/40 - 38s - loss: 0.5909 - accuracy: 0.7849 - val_accuracy: 0.7250 - 38s/epoch - 0ms/step\n",
      "35/40 - 39s - loss: 0.5857 - accuracy: 0.7880 - val_accuracy: 0.7274 - 39s/epoch - 0ms/step\n",
      "36/40 - 37s - loss: 0.5832 - accuracy: 0.7878 - val_accuracy: 0.7330 - 37s/epoch - 0ms/step\n",
      "37/40 - 37s - loss: 0.5622 - accuracy: 0.7948 - val_accuracy: 0.7276 - 37s/epoch - 0ms/step\n",
      "38/40 - 37s - loss: 0.5582 - accuracy: 0.7974 - val_accuracy: 0.7378 - 37s/epoch - 0ms/step\n",
      "39/40 - 37s - loss: 0.5472 - accuracy: 0.7982 - val_accuracy: 0.7244 - 37s/epoch - 0ms/step\n",
      "40/40 - 37s - loss: 0.5471 - accuracy: 0.7999 - val_accuracy: 0.7264 - 37s/epoch - 0ms/step\n",
      "Time 1470.6 sec\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "noise_types = ['symmetric', 'asymmetric']\n",
    "for noise_type in noise_types:\n",
    "    noise_level = 0.8\n",
    "    print(f\"####### Training with {noise_type} noise level: {noise_level} ########\")\n",
    "    run_train_harness(noise_level, noise_type)\n",
    "    print(\"\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "149a3e35-4b1a-4330-a382-4cb2e0f2fda7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####### Training with asymmetric noise level: 0.8 ########\n",
      "Files already downloaded and verified\n",
      "asy:  50000   0.8\n",
      "1/40 - 37s - loss: 2.0909 - accuracy: 0.1774 - val_accuracy: 0.1808 - 37s/epoch - 0ms/step\n",
      "2/40 - 37s - loss: 2.0818 - accuracy: 0.1804 - val_accuracy: 0.1784 - 37s/epoch - 0ms/step\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[106], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m noise_level \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.8\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m####### Training with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnoise_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m noise level: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnoise_level\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ########\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m \u001b[43mrun_train_harness\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnoise_level\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnoise_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[101], line 24\u001b[0m, in \u001b[0;36mrun_train_harness\u001b[1;34m(noise_level, noise_type)\u001b[0m\n\u001b[0;32m     21\u001b[0m lr_period, lr_decay \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m0.9\u001b[39m\n\u001b[0;32m     22\u001b[0m net \u001b[38;5;241m=\u001b[39m vgg(small_conv_arch)\n\u001b[1;32m---> 24\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr_period\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr_decay\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[99], line 93\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(net, train_iter, valid_iter, num_epochs, lr, wd, devices, lr_period, lr_decay)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (features, labels) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_iter):\n\u001b[0;32m     92\u001b[0m     timer\u001b[38;5;241m.\u001b[39mstart()\n\u001b[1;32m---> 93\u001b[0m     l, acc \u001b[38;5;241m=\u001b[39m \u001b[43md2l\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_batch_ch13\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevices\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevices\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     94\u001b[0m     metric\u001b[38;5;241m.\u001b[39madd(l, acc, labels\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m     95\u001b[0m     timer\u001b[38;5;241m.\u001b[39mstop()\n",
      "File \u001b[1;32mD:\\miniconda3\\envs\\myenv\\lib\\site-packages\\d2l\\torch.py:1496\u001b[0m, in \u001b[0;36mtrain_batch_ch13\u001b[1;34m(net, X, y, loss, trainer, devices)\u001b[0m\n\u001b[0;32m   1494\u001b[0m trainer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m   1495\u001b[0m train_loss_sum \u001b[38;5;241m=\u001b[39m l\u001b[38;5;241m.\u001b[39msum()\n\u001b[1;32m-> 1496\u001b[0m train_acc_sum \u001b[38;5;241m=\u001b[39m \u001b[43md2l\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccuracy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m train_loss_sum, train_acc_sum\n",
      "File \u001b[1;32mD:\\miniconda3\\envs\\myenv\\lib\\site-packages\\d2l\\torch.py:3195\u001b[0m, in \u001b[0;36maccuracy\u001b[1;34m(y_hat, y)\u001b[0m\n\u001b[0;32m   3193\u001b[0m     y_hat \u001b[38;5;241m=\u001b[39m d2l\u001b[38;5;241m.\u001b[39margmax(y_hat, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m   3194\u001b[0m cmp \u001b[38;5;241m=\u001b[39m d2l\u001b[38;5;241m.\u001b[39mastype(y_hat, y\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;241m==\u001b[39m y\n\u001b[1;32m-> 3195\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43md2l\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduce_sum\u001b[49m\u001b[43m(\u001b[49m\u001b[43md2l\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "noise_types = ['asymmetric']\n",
    "for noise_type in noise_types:\n",
    "    noise_level = 0.8\n",
    "    print(f\"####### Training with {noise_type} noise level: {noise_level} ########\")\n",
    "    run_train_harness(noise_level, noise_type)\n",
    "    print(\"\\n\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
